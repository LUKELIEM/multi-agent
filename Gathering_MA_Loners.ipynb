{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent Gathering Environment\n",
    "\n",
    "In this notebook, we evolve the code from HumanCompatibleAI's single-agent version to full-fledged multi-agent reinforcement learning.\n",
    "\n",
    "* 1st Iteration - Policy Gradient agent vs 1+ Random Agent\n",
    "* 2nd iteration - Train Policy Gradient agent vs  1+ previously-trained PG agent\n",
    "* 3rd iteration - Train multiple Policy Gradient agents together\n",
    "\n",
    "We will implement the code changes in the Python files (.py) directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.4\n",
      "Pytorch version: 0.2.0_3\n",
      "OpenAI Gym version: 0.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import platform\n",
    "import torch\n",
    "import gym\n",
    "\n",
    "from env import GatheringEnv   # This is the Game Environment\n",
    "# from model import Policy   Use the Policy defined below instead\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Pytorch version: {}\".format(torch.__version__))\n",
    "print(\"OpenAI Gym version: {}\".format(gym.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1st Iteration - Policy Gradient agent vs 1+ Random Agent\n",
    "\n",
    "The HumanCompatibleAI's code only allows one agent to be trained in a Gathering environment with the other agents being random agents. This is because the weights are saved and loaded from a fixed single file.\n",
    "\n",
    "To get the code to accept multiple trained agents, the Policy class has been changed to accept agent index and to allow each agent to save and load weights from its own model file. The code now expects each agent to have its own set of trained weights:\n",
    "\n",
    "* agent-1-model.pkl\n",
    "* agent-2-model.pkl\n",
    "* etc....\n",
    "\n",
    "In addition, we created the Rdn_Policy class to accommodate random agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    # an index parameter is needed to allow for multiple learning agents later\n",
    "    def __init__(self, observation_size, agent_idx=1):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(observation_size, 128)\n",
    "        self.affine2 = nn.Linear(128, 8)\n",
    "\n",
    "        self.saved_actions = []\n",
    "        self.rewards = []\n",
    "        self.idx = agent_idx   # This allows multiple learning agents\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.affine1(x))\n",
    "        action_scores = self.affine2(x)\n",
    "        return F.softmax(action_scores)\n",
    "\n",
    "    # The weights should be allowed to be saved into and load from agent-indexed model files\n",
    "    # e.g. agent-1-model.pkl, agent-2-model.pkl, etc.\n",
    "    def save_weights(self):\n",
    "        file_name = 'agent-'+str(self.idx)+'-model.pkl'\n",
    "        torch.save(self.state_dict(), file_name)   \n",
    "\n",
    "    def load_weights(self):\n",
    "        file_name = 'agent-'+str(self.idx)+'-model.pkl'\n",
    "        if not os.path.exists(file_name):\n",
    "                raise ValueError('map not found: ' + file_name)\n",
    "        self.load_state_dict(torch.load(file_name))\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        probs = self(Variable(state))\n",
    "        action = probs.multinomial()\n",
    "        self.saved_actions.append(action)\n",
    "        return action.data[0, 0]\n",
    "\n",
    "\n",
    "# Just a dumb random agent\n",
    "class Rdn_Policy():\n",
    "    def __init__(self):\n",
    "        super(Rdn_Policy, self).__init__()\n",
    "\n",
    "    def select_action(self, state):\n",
    "        return random.randrange(0, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 PG agent vs multiple random agents\n",
    "\n",
    "We get the code to run a PG agent against multiple random agents after making some change to GatheringEnv() Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load agent 0\n",
      "Load agent 1\n",
      "Load agent 2\n",
      "Load agent 3\n",
      "[1, 3, 2, 3]\n",
      "[3, 4, 1, 7]\n",
      "[2, 6, 6, 0]\n",
      "[6, 5, 3, 0]\n",
      "[0, 7, 0, 2]\n",
      "[1, 0, 6, 1]\n",
      "[3, 2, 6, 0]\n",
      "[1, 0, 1, 6]\n",
      "[0, 7, 2, 6]\n",
      "[6, 5, 1, 7]\n",
      "[1, 3, 3, 6]\n",
      "[2, 6, 0, 6]\n",
      "[2, 4, 6, 4]\n",
      "[2, 3, 5, 5]\n",
      "[2, 7, 7, 0]\n",
      "[2, 2, 5, 7]\n",
      "[3, 5, 4, 6]\n",
      "[3, 0, 5, 5]\n",
      "[6, 3, 7, 6]\n",
      "[0, 5, 4, 4]\n",
      "[2, 1, 3, 0]\n",
      "[2, 4, 4, 5]\n",
      "[2, 3, 4, 3]\n",
      "[2, 2, 0, 5]\n",
      "[3, 1, 1, 3]\n",
      "[1, 6, 7, 5]\n",
      "[1, 3, 0, 4]\n",
      "[1, 3, 7, 7]\n",
      "[3, 6, 3, 7]\n",
      "[5, 1, 0, 1]\n",
      "Agent1 aggressiveness is 0.10\n",
      "Agent1 reward is 114\n",
      "Agent2 aggressiveness is 0.10\n",
      "Agent2 reward is 0\n",
      "Agent3 aggressiveness is 0.12\n",
      "Agent3 reward is 0\n",
      "Agent4 aggressiveness is 0.15\n",
      "Agent4 reward is 0\n"
     ]
    }
   ],
   "source": [
    "# from model import *    # Use the Policy and Rdn_Policy classes instead\n",
    "\n",
    "# There will be 4 agents - 1 AI agents, 3 random agents\n",
    "num_ai_agents = 1\n",
    "num_rdn_agents = 3\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "ai_agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "rewards = []\n",
    "\n",
    "env = GatheringEnv(n_agents=num_agents, map_name='default')\n",
    "\n",
    "# Env API is similar to that of OpenAI Gym\n",
    "state_n = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Load AI agents with trained weights\n",
    "for i in range(num_ai_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Policy(env.state_size, i+1))\n",
    "    ai_agents[i].load_weights()\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Rdn_Policy())\n",
    "\n",
    "# Initialize AI and random agent data\n",
    "for i in range(num_agents):\n",
    "    actions = [0 for i in range(num_agents)]\n",
    "    tags = [0 for i in range(num_agents)]\n",
    "    rewards = [0 for i in range(num_agents)]\n",
    "\n",
    "n_steps = 300\n",
    "\n",
    "# Render for n_steps steps\n",
    "for step in range(n_steps):\n",
    "    # Load AI agent with trained weights\n",
    "    for i in range(num_agents):\n",
    "        actions[i] = ai_agents[i].select_action(state_n[i])\n",
    "        if actions[i] is 6:\n",
    "            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print (actions)    \n",
    "            \n",
    "    state_n, reward_n, done_n, info_n = env.step(actions)\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        rewards[i] += reward_n[i]    # Accumulate rewards for each agent\n",
    "        \n",
    "    if any(done_n):\n",
    "        break\n",
    "    env.render()\n",
    "    time.sleep(1/30)  # Change speed of video rendering\n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "\n",
    "# Print out statistics of all agents\n",
    "for i in range(num_agents):\n",
    "    print (\"Agent{} aggressiveness is {:.2f}\".format(i+1, tags[i]/n_steps))\n",
    "    print (\"Agent{} reward is {:d}\".format(i+1, rewards[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-agents with previously trained weights\n",
    "\n",
    "When we load 3 previously trained PG agents, and they play well against the 2 random agents and each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load agent 0\n",
      "Load agent 1\n",
      "Load agent 2\n",
      "Load agent 3\n",
      "Load agent 4\n",
      "[2, 6, 1, 2, 4]\n",
      "[0, 0, 3, 3, 7]\n",
      "[0, 0, 0, 3, 4]\n",
      "[0, 2, 1, 3, 2]\n",
      "[3, 0, 0, 1, 7]\n",
      "[6, 6, 4, 7, 3]\n",
      "[2, 1, 1, 2, 0]\n",
      "[0, 6, 0, 4, 0]\n",
      "[5, 6, 0, 5, 3]\n",
      "[0, 3, 6, 1, 4]\n",
      "[3, 1, 1, 5, 4]\n",
      "[0, 2, 1, 0, 7]\n",
      "[2, 6, 1, 5, 2]\n",
      "[0, 1, 4, 5, 6]\n",
      "[0, 0, 0, 7, 6]\n",
      "[6, 1, 0, 5, 3]\n",
      "[6, 1, 2, 6, 3]\n",
      "[6, 1, 3, 6, 3]\n",
      "[5, 1, 3, 0, 2]\n",
      "[0, 4, 1, 7, 6]\n",
      "[3, 7, 1, 3, 7]\n",
      "[0, 2, 4, 5, 3]\n",
      "[6, 4, 6, 6, 7]\n",
      "[3, 7, 4, 5, 3]\n",
      "[6, 4, 0, 5, 4]\n",
      "[1, 0, 1, 4, 1]\n",
      "[0, 0, 5, 2, 2]\n",
      "[3, 0, 0, 0, 4]\n",
      "[3, 1, 4, 5, 2]\n",
      "[2, 3, 6, 3, 5]\n",
      "Agent1 aggressiveness is 0.12\n",
      "Agent1 reward is 7\n",
      "Agent2 aggressiveness is 0.13\n",
      "Agent2 reward is 47\n",
      "Agent3 aggressiveness is 0.14\n",
      "Agent3 reward is 19\n",
      "Agent4 aggressiveness is 0.09\n",
      "Agent4 reward is 0\n",
      "Agent5 aggressiveness is 0.10\n",
      "Agent5 reward is 0\n"
     ]
    }
   ],
   "source": [
    "from model import *    # Use the Policy and Rdn_policy defined in model.py\n",
    "\n",
    "# There will be 5 agents - 3 AI agents, 2 random agents\n",
    "num_ai_agents = 3\n",
    "num_rdn_agents = 2\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "ai_agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "rewards = []\n",
    "\n",
    "env = GatheringEnv(n_agents=num_agents, map_name='default')\n",
    "\n",
    "# Env API is similar to that of OpenAI Gym\n",
    "state_n = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Load AI agents with trained weights\n",
    "for i in range(num_ai_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Policy(env.state_size, i+1))\n",
    "    ai_agents[i].load_weights()\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Rdn_Policy())\n",
    "\n",
    "# Initialize AI and random agent data\n",
    "for i in range(num_agents):\n",
    "    actions = [0 for i in range(num_agents)]\n",
    "    tags = [0 for i in range(num_agents)]\n",
    "    rewards = [0 for i in range(num_agents)]\n",
    "\n",
    "n_steps = 300\n",
    "\n",
    "# Render for n_steps steps\n",
    "for step in range(n_steps):\n",
    "    # Load AI agent with trained weights\n",
    "    for i in range(num_agents):\n",
    "        actions[i] = ai_agents[i].select_action(state_n[i])\n",
    "        if actions[i] is 6:\n",
    "            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print (actions)    \n",
    "            \n",
    "    state_n, reward_n, done_n, info_n = env.step(actions)\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        rewards[i] += reward_n[i]    # Accumulate rewards for each agent\n",
    "        \n",
    "    if any(done_n):\n",
    "        break\n",
    "    env.render()\n",
    "    time.sleep(1/30)  # Change speed of video rendering\n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "\n",
    "# Print out statistics of all agents\n",
    "for i in range(num_agents):\n",
    "    print (\"Agent{} aggressiveness is {:.2f}\".format(i+1, tags[i]/n_steps))\n",
    "    print (\"Agent{} reward is {:d}\".format(i+1, rewards[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration 2 - Train PG agent vs 1+ previously-trained PG agent\n",
    "\n",
    "We train a PG agent in a multi-agent environment with previously trained PG agents. These previously trained PG agents will not learn during the training, their policies are thus **static**.\n",
    "\n",
    "To allow for the training multiple learning agents, finish_episode() will need to be modified to be able to backprop on the parameters of multiple agents. We will save this for the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner agent 0\n",
      "Load static agent 1\n",
      "Load static agent 2\n",
      "Load static agent 3\n",
      "Episode 20:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.06\n",
      "Episode 40:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.13\n",
      "Episode 60:\n",
      "Learner 0\tLast reward:     1\tAverage reward: 0.25\n",
      "Episode 80:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.25\n",
      "Episode 100:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.29\n",
      "Episode 120:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.28\n",
      "Episode 140:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.37\n",
      "Episode 160:\n",
      "Learner 0\tLast reward:     1\tAverage reward: 0.67\n",
      "Episode 180:\n",
      "Learner 0\tLast reward:    11\tAverage reward: 1.94\n",
      "Episode 200:\n",
      "Learner 0\tLast reward:    34\tAverage reward: 5.11\n",
      "Episode 220:\n",
      "Learner 0\tLast reward:    50\tAverage reward: 9.03\n",
      "Episode 240:\n",
      "Learner 0\tLast reward:    37\tAverage reward: 13.92\n",
      "Episode 260:\n",
      "Learner 0\tLast reward:    54\tAverage reward: 21.07\n",
      "Episode 280:\n",
      "Learner 0\tLast reward:    60\tAverage reward: 28.82\n",
      "Episode 300:\n",
      "Learner 0\tLast reward:    62\tAverage reward: 35.23\n",
      "Episode 320:\n",
      "Learner 0\tLast reward:    71\tAverage reward: 41.40\n",
      "Episode 340:\n",
      "Learner 0\tLast reward:    66\tAverage reward: 49.19\n",
      "Episode 360:\n",
      "Learner 0\tLast reward:    82\tAverage reward: 56.13\n",
      "Episode 380:\n",
      "Learner 0\tLast reward:    74\tAverage reward: 62.42\n",
      "Episode 400:\n",
      "Learner 0\tLast reward:   118\tAverage reward: 69.53\n",
      "Episode 420:\n",
      "Learner 0\tLast reward:   125\tAverage reward: 75.20\n",
      "Episode 440:\n",
      "Learner 0\tLast reward:   102\tAverage reward: 80.89\n",
      "Episode 460:\n",
      "Learner 0\tLast reward:    94\tAverage reward: 85.29\n",
      "Episode 480:\n",
      "Learner 0\tLast reward:   110\tAverage reward: 89.51\n",
      "Episode 500:\n",
      "Learner 0\tLast reward:   113\tAverage reward: 94.00\n",
      "Episode 520:\n",
      "Learner 0\tLast reward:   126\tAverage reward: 97.44\n",
      "Episode 540:\n",
      "Learner 0\tLast reward:    97\tAverage reward: 97.64\n",
      "Episode 560:\n",
      "Learner 0\tLast reward:   101\tAverage reward: 100.13\n",
      "Episode 580:\n",
      "Learner 0\tLast reward:   108\tAverage reward: 102.31\n",
      "Episode 600:\n",
      "Learner 0\tLast reward:    92\tAverage reward: 103.82\n",
      "Episode 620:\n",
      "Learner 0\tLast reward:   121\tAverage reward: 105.81\n",
      "Episode 640:\n",
      "Learner 0\tLast reward:   124\tAverage reward: 108.55\n",
      "Episode 660:\n",
      "Learner 0\tLast reward:    96\tAverage reward: 109.18\n",
      "Episode 680:\n",
      "Learner 0\tLast reward:   102\tAverage reward: 110.04\n",
      "Episode 700:\n",
      "Learner 0\tLast reward:   137\tAverage reward: 111.77\n",
      "Episode 720:\n",
      "Learner 0\tLast reward:   153\tAverage reward: 113.15\n",
      "Episode 740:\n",
      "Learner 0\tLast reward:   121\tAverage reward: 114.47\n",
      "Episode 760:\n",
      "Learner 0\tLast reward:    96\tAverage reward: 114.55\n",
      "Episode 780:\n",
      "Learner 0\tLast reward:   115\tAverage reward: 115.17\n",
      "Episode 800:\n",
      "Learner 0\tLast reward:   134\tAverage reward: 116.70\n",
      "Episode 820:\n",
      "Learner 0\tLast reward:   109\tAverage reward: 118.17\n",
      "Episode 840:\n",
      "Learner 0\tLast reward:    94\tAverage reward: 118.64\n",
      "Episode 860:\n",
      "Learner 0\tLast reward:   111\tAverage reward: 120.82\n",
      "Episode 880:\n",
      "Learner 0\tLast reward:   118\tAverage reward: 122.39\n",
      "Episode 900:\n",
      "Learner 0\tLast reward:   114\tAverage reward: 122.52\n",
      "Episode 920:\n",
      "Learner 0\tLast reward:   117\tAverage reward: 122.12\n",
      "Episode 940:\n",
      "Learner 0\tLast reward:   157\tAverage reward: 124.56\n",
      "Episode 960:\n",
      "Learner 0\tLast reward:    97\tAverage reward: 125.37\n",
      "Episode 980:\n",
      "Learner 0\tLast reward:   165\tAverage reward: 127.77\n",
      "Episode 1000:\n",
      "Learner 0\tLast reward:   125\tAverage reward: 127.02\n"
     ]
    }
   ],
   "source": [
    "# Adapted from https://github.com/pytorch/examples/blob/2dca104/reinforcement_learning/reinforce.py\n",
    "# Licensed under BSD 3-clause: https://github.com/pytorch/examples/blob/2dca10404443ce3178343c07ba6e22af13efb006/LICENSE\n",
    "\n",
    "import random\n",
    "from itertools import count\n",
    "\n",
    "from env import GatheringEnv\n",
    "from model import *    # Use the Policy and Rdn_policy defined in model.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "\n",
    "# We remove the argparse code and replace with hard parameters\n",
    "gamma = 0.99\n",
    "seed = 543\n",
    "render=False\n",
    "log_interval=20\n",
    "target_reward = 500\n",
    "\n",
    "# There will be 4 agents - 1 learning agents, 3 static agents\n",
    "num_learners = 1\n",
    "num_statics = 3\n",
    "num_agents = num_learners+num_statics  # just the sum of the two\n",
    "\n",
    "# Data structure for agents (learning and static)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "rewards = []\n",
    "\n",
    "# Start the Gathering environment\n",
    "env = GatheringEnv(n_agents=num_agents, map_name='default')\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Initialize learner agents\n",
    "for i in range(num_learners):\n",
    "    print(\"Learner agent {}\".format(i+1))\n",
    "    agents.append(Policy(env.state_size, i+1))  # No weights loaded\n",
    "\n",
    "# Load static agents\n",
    "for i in range(num_learners, num_agents):\n",
    "    print(\"Load static agent {}\".format(i+1))\n",
    "    agents.append(Policy(env.state_size, i+1))\n",
    "    agents[i].load_weights()\n",
    "    \n",
    "# Initialize all agent data\n",
    "for i in range(num_agents):\n",
    "    actions = [0 for i in range(num_agents)]\n",
    "    tags = [0 for i in range(num_agents)]\n",
    "    rewards = [0 for i in range(num_agents)]\n",
    "    \n",
    "learners_params = agents[0].parameters()   # For now, there is only 1 learner\n",
    "# For multiple learning agents later on, replace with\n",
    "# params = list(fc1.parameters()) + list(fc2.parameters())\n",
    "\n",
    "optimizer = optim.Adam(learners_params, lr=1e-3)   # Only agent 1 will learn\n",
    "\n",
    "# This is the task list to finish a game episode\n",
    "def finish_episode():\n",
    "    \"\"\" \n",
    "    Based on REINFORCE, policy gradient is calculated at the end of an episode.\n",
    "    It is then used to update the Policy's weights\n",
    "    \"\"\"\n",
    "    \n",
    "    # Our code only accommodates 1 learning agent.\n",
    "    # Reward for each time step is stored in the list policy.rewards[] --> r(t)\n",
    "    R = 0  # noqa\n",
    "    rewards = []\n",
    "    for r in agents[0].rewards[::-1]:\n",
    "        R = r + gamma * R  # noqa\n",
    "        rewards.insert(0, R)\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\n",
    "    \n",
    "    # Calculate policy gradient Σ_t[r(t) ∇_θ log(π_θ(s_t,a_t))\n",
    "    for action, r in zip(agents[0].saved_actions, rewards):\n",
    "        action.reinforce(r)     # Note that action.reinforce has been deprecated since torch V0.3\n",
    "    optimizer.zero_grad()\n",
    "    autograd.backward(agents[0].saved_actions, [None for _ in agents[0].saved_actions])\n",
    "    optimizer.step()\n",
    "    \n",
    "    del agents[0].rewards[:]\n",
    "    del agents[0].saved_actions[:]\n",
    "\n",
    "\n",
    "# Keep track of rewards learned by learners\n",
    "running_reward = [0 for i in range(num_learners)]   # running average\n",
    "best_reward = [0 for i in range(num_learners)]    # best running average for storing best_model\n",
    "episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "\n",
    "for i_episode in range(1,1001):   # For each game episode\n",
    "    \n",
    "    # Some basic initialization\n",
    "    state = env.reset()\n",
    "    for i in range(num_learners):\n",
    "        episode_reward[i] = 0   # initialize episode rewards for learners\n",
    "    \n",
    "    for t in range(1000):  # Don't infinite loop while learning\n",
    "        \n",
    "        # 1. learning and static agents select their action\n",
    "        for i in range(num_agents):\n",
    "            actions[i] = agents[i].select_action(state[i])\n",
    "            if actions[i] is 6:\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "       \n",
    "        # 2. environment accepts action from learning and static agents and \n",
    "        # doles out next state, reward and if the episode is done\n",
    "        state_n, reward_n, done_n, _ = env.step(actions)\n",
    "        \n",
    "        state = state_n\n",
    "        done = done_n[0]\n",
    "        \n",
    "        if render:   # render learning if set to True\n",
    "            env.render()\n",
    "            \n",
    "        # For learner agents only, generate reward statistics and reward stack for REINFORCE\n",
    "        for i in range(num_learners):\n",
    "            agents[i].rewards.append(reward_n[i])  # Stack rewards for REINFORCE\n",
    "            episode_reward[i] += reward_n[i]   # accumulate episode reward \n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Update reward statistics for learners\n",
    "    for i in range(num_learners):\n",
    "        if running_reward[i] is None:\n",
    "            running_reward[i] = episode_reward[i]\n",
    "        running_reward[i] = running_reward[i] * 0.99 + episode_reward[i] * 0.01\n",
    "    \n",
    "    finish_episode()    # Finish up game episode\n",
    "        \n",
    "    if i_episode % log_interval == 0:\n",
    "        print('Episode {}:'.format(i_episode))\n",
    "        for i in range(num_learners):\n",
    "            # Display reward stats for learners\n",
    "            print('Learner {}\\tLast reward: {:5d}\\tAverage reward: {:.2f}'.format(\n",
    "            i, episode_reward[i], running_reward[i]))\n",
    "            \n",
    "            # Only save NN weights if running_reward is better than best_reward\n",
    "            if best_reward[i]is None:\n",
    "                best_reward[i] = running_reward[i]\n",
    "                agents[i].save_weights()   # Save NN weights for learner if this is the first save\n",
    "            else:\n",
    "                if running_reward[i] > best_reward[i]:\n",
    "                    agents[i].save_weights()   # Save NN weights for learner only if it performs better\n",
    "        \n",
    "env.close()  # Close the rendering window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play - Newly Trained PG1 vs Trained PG2-4\n",
    "\n",
    "We now play the newly trained PG agents against the 3 previously-trained PG agents it was trained against.\n",
    "    \n",
    "The newly trained agent (Agent 1) is able to overpower the other 3 agents, but not being overly aggressive.\n",
    "\n",
    "Agent1 aggressiveness is 0.09  \n",
    "Agent1 reward is 138  \n",
    "Agent2 aggressiveness is 0.13  \n",
    "Agent2 reward is 55  \n",
    "Agent3 aggressiveness is 0.12  \n",
    "Agent3 reward is 53  \n",
    "Agent4 aggressiveness is 0.13  \n",
    "Agent4 reward is 22  \n",
    "\n",
    "It appears to always tag to the right when the other 3 agents are within his sight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load agent 0\n",
      "Load agent 1\n",
      "Load agent 2\n",
      "Load agent 3\n",
      "[4, 4, 5, 4]\n",
      "[1, 0, 0, 2]\n",
      "[0, 5, 1, 5]\n",
      "[1, 0, 0, 4]\n",
      "[1, 0, 0, 6]\n",
      "[0, 1, 0, 7]\n",
      "[1, 0, 2, 4]\n",
      "[1, 0, 1, 3]\n",
      "[4, 2, 0, 2]\n",
      "[4, 0, 0, 0]\n",
      "[6, 0, 0, 0]\n",
      "[0, 3, 0, 5]\n",
      "[4, 2, 4, 1]\n",
      "[3, 0, 0, 1]\n",
      "[1, 0, 0, 3]\n",
      "[1, 0, 0, 6]\n",
      "[1, 0, 7, 4]\n",
      "[2, 0, 4, 2]\n",
      "[1, 0, 0, 0]\n",
      "[3, 5, 0, 3]\n",
      "[4, 0, 0, 7]\n",
      "[7, 1, 1, 4]\n",
      "[0, 0, 5, 4]\n",
      "[0, 0, 3, 7]\n",
      "[1, 0, 0, 2]\n",
      "[1, 1, 0, 2]\n",
      "[7, 0, 6, 7]\n",
      "[1, 0, 0, 7]\n",
      "[0, 0, 1, 4]\n",
      "[0, 0, 0, 2]\n",
      "[3, 1, 0, 1]\n",
      "[1, 0, 0, 4]\n",
      "[1, 6, 1, 1]\n",
      "[7, 0, 0, 0]\n",
      "[4, 7, 0, 6]\n",
      "[1, 0, 5, 4]\n",
      "[0, 5, 6, 1]\n",
      "[7, 0, 7, 7]\n",
      "[7, 0, 0, 5]\n",
      "[1, 0, 1, 4]\n",
      "[1, 3, 0, 7]\n",
      "[0, 7, 0, 6]\n",
      "[0, 5, 5, 6]\n",
      "[0, 0, 0, 1]\n",
      "[0, 4, 6, 7]\n",
      "[4, 0, 0, 1]\n",
      "[4, 0, 1, 0]\n",
      "[1, 0, 5, 6]\n",
      "[0, 0, 5, 1]\n",
      "[0, 1, 1, 5]\n",
      "[2, 0, 0, 7]\n",
      "[1, 0, 0, 6]\n",
      "[6, 0, 0, 1]\n",
      "[0, 0, 0, 7]\n",
      "[1, 1, 6, 5]\n",
      "[1, 0, 0, 5]\n",
      "[0, 4, 0, 3]\n",
      "[3, 0, 1, 1]\n",
      "[4, 5, 0, 1]\n",
      "[1, 0, 0, 0]\n",
      "[1, 5, 0, 2]\n",
      "[5, 6, 0, 3]\n",
      "[3, 6, 0, 3]\n",
      "[1, 3, 0, 0]\n",
      "[4, 5, 5, 3]\n",
      "[0, 0, 0, 3]\n",
      "[0, 1, 0, 6]\n",
      "[0, 1, 0, 1]\n",
      "[1, 1, 0, 1]\n",
      "[0, 1, 0, 2]\n",
      "[3, 1, 0, 1]\n",
      "[5, 1, 0, 4]\n",
      "[6, 0, 6, 1]\n",
      "[3, 0, 7, 3]\n",
      "[1, 0, 0, 1]\n",
      "[2, 0, 0, 3]\n",
      "[1, 6, 0, 7]\n",
      "[1, 1, 5, 5]\n",
      "[1, 0, 3, 0]\n",
      "[1, 0, 1, 0]\n",
      "[1, 5, 5, 3]\n",
      "[3, 2, 0, 2]\n",
      "[1, 5, 3, 7]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 0]\n",
      "[0, 0, 0, 2]\n",
      "[6, 0, 1, 5]\n",
      "[1, 6, 0, 6]\n",
      "[1, 7, 0, 1]\n",
      "[1, 0, 0, 0]\n",
      "[1, 0, 0, 3]\n",
      "[6, 0, 0, 6]\n",
      "[0, 6, 4, 3]\n",
      "[0, 0, 0, 3]\n",
      "[3, 1, 1, 7]\n",
      "[1, 0, 1, 2]\n",
      "[6, 0, 0, 0]\n",
      "[1, 0, 1, 2]\n",
      "[6, 0, 1, 1]\n",
      "[6, 0, 7, 3]\n",
      "Agent1 aggressiveness is 0.09\n",
      "Agent1 reward is 168\n",
      "Agent2 aggressiveness is 0.10\n",
      "Agent2 reward is 41\n",
      "Agent3 aggressiveness is 0.11\n",
      "Agent3 reward is 35\n",
      "Agent4 aggressiveness is 0.12\n",
      "Agent4 reward is 0\n"
     ]
    }
   ],
   "source": [
    "from model import *    # Use the Policy and Rdn_policy defined in model.py\n",
    "\n",
    "# There will be 4 agents - 3 AI agents, 1 random agent\n",
    "num_ai_agents = 3\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "ai_agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "rewards = []\n",
    "\n",
    "env = GatheringEnv(n_agents=num_agents, map_name='default')\n",
    "\n",
    "# Env API is similar to that of OpenAI Gym\n",
    "state_n = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Load AI agents with trained weights\n",
    "for i in range(num_ai_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Policy(env.state_size, i+1))\n",
    "    ai_agents[i].load_weights()\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Rdn_Policy())\n",
    "\n",
    "# Initialize AI and random agent data\n",
    "for i in range(num_agents):\n",
    "    actions = [0 for i in range(num_agents)]\n",
    "    tags = [0 for i in range(num_agents)]\n",
    "    rewards = [0 for i in range(num_agents)]\n",
    "\n",
    "n_steps = 1000\n",
    "\n",
    "# Render for n_steps steps\n",
    "for step in range(n_steps):\n",
    "    # Load AI agent with trained weights\n",
    "    for i in range(num_agents):\n",
    "        actions[i] = ai_agents[i].select_action(state_n[i])\n",
    "        if actions[i] is 6:\n",
    "            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print (actions)    \n",
    "            \n",
    "    state_n, reward_n, done_n, info_n = env.step(actions)\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        rewards[i] += reward_n[i]    # Accumulate rewards for each agent\n",
    "        \n",
    "    if any(done_n):\n",
    "        break\n",
    "    env.render()\n",
    "    time.sleep(1/30)  # Change speed of video rendering\n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "\n",
    "# Print out statistics of all agents\n",
    "for i in range(num_agents):\n",
    "    print (\"Agent{} aggressiveness is {:.2f}\".format(i+1, tags[i]/n_steps))\n",
    "    print (\"Agent{} reward is {:d}\".format(i+1, rewards[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play - Enable Multi-agent Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner agent 1\n",
      "Learner agent 2\n",
      "Load static agent 3\n",
      "Load static agent 4\n",
      "Episode 20:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.05\n",
      "Learner 1\tLast reward:     0\tAverage reward: 0.10\n",
      "Episode 40:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.20\n",
      "Learner 1\tLast reward:     0\tAverage reward: 0.15\n",
      "Episode 60:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.35\n",
      "Learner 1\tLast reward:     6\tAverage reward: 0.22\n",
      "Episode 80:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.47\n",
      "Learner 1\tLast reward:     0\tAverage reward: 0.20\n",
      "Episode 100:\n",
      "Learner 0\tLast reward:     0\tAverage reward: 0.55\n",
      "Learner 1\tLast reward:     0\tAverage reward: 0.25\n",
      "Episode 120:\n",
      "Learner 0\tLast reward:     7\tAverage reward: 1.01\n",
      "Learner 1\tLast reward:     0\tAverage reward: 0.35\n",
      "Episode 140:\n",
      "Learner 0\tLast reward:     3\tAverage reward: 1.39\n",
      "Learner 1\tLast reward:     0\tAverage reward: 0.68\n",
      "Episode 160:\n",
      "Learner 0\tLast reward:    19\tAverage reward: 4.09\n",
      "Learner 1\tLast reward:    14\tAverage reward: 1.55\n",
      "Episode 180:\n",
      "Learner 0\tLast reward:    70\tAverage reward: 10.28\n",
      "Learner 1\tLast reward:    30\tAverage reward: 4.87\n",
      "Episode 200:\n",
      "Learner 0\tLast reward:    63\tAverage reward: 21.42\n",
      "Learner 1\tLast reward:    27\tAverage reward: 10.64\n",
      "Episode 220:\n",
      "Learner 0\tLast reward:   141\tAverage reward: 38.92\n",
      "Learner 1\tLast reward:    35\tAverage reward: 17.46\n",
      "Episode 240:\n",
      "Learner 0\tLast reward:   161\tAverage reward: 57.65\n",
      "Learner 1\tLast reward:    61\tAverage reward: 25.08\n",
      "Episode 260:\n",
      "Learner 0\tLast reward:   200\tAverage reward: 76.60\n",
      "Learner 1\tLast reward:    50\tAverage reward: 31.50\n",
      "Episode 280:\n",
      "Learner 0\tLast reward:   157\tAverage reward: 92.61\n",
      "Learner 1\tLast reward:   100\tAverage reward: 40.58\n",
      "Episode 300:\n",
      "Learner 0\tLast reward:   167\tAverage reward: 108.83\n",
      "Learner 1\tLast reward:   134\tAverage reward: 52.15\n",
      "Episode 320:\n",
      "Learner 0\tLast reward:   223\tAverage reward: 128.48\n",
      "Learner 1\tLast reward:   136\tAverage reward: 65.17\n",
      "Episode 340:\n",
      "Learner 0\tLast reward:   220\tAverage reward: 148.08\n",
      "Learner 1\tLast reward:   119\tAverage reward: 77.52\n",
      "Episode 360:\n",
      "Learner 0\tLast reward:   289\tAverage reward: 168.72\n",
      "Learner 1\tLast reward:   112\tAverage reward: 87.81\n",
      "Episode 380:\n",
      "Learner 0\tLast reward:   228\tAverage reward: 182.09\n",
      "Learner 1\tLast reward:   215\tAverage reward: 104.69\n",
      "Episode 400:\n",
      "Learner 0\tLast reward:   219\tAverage reward: 193.89\n",
      "Learner 1\tLast reward:   132\tAverage reward: 118.90\n",
      "Episode 420:\n",
      "Learner 0\tLast reward:   257\tAverage reward: 203.62\n",
      "Learner 1\tLast reward:   148\tAverage reward: 123.85\n",
      "Episode 440:\n",
      "Learner 0\tLast reward:   265\tAverage reward: 217.61\n",
      "Learner 1\tLast reward:   179\tAverage reward: 130.57\n",
      "Episode 460:\n",
      "Learner 0\tLast reward:   250\tAverage reward: 225.37\n",
      "Learner 1\tLast reward:   152\tAverage reward: 136.15\n",
      "Episode 480:\n",
      "Learner 0\tLast reward:   363\tAverage reward: 239.15\n",
      "Learner 1\tLast reward:    89\tAverage reward: 140.25\n",
      "Episode 500:\n",
      "Learner 0\tLast reward:   184\tAverage reward: 238.57\n",
      "Learner 1\tLast reward:   233\tAverage reward: 148.77\n",
      "Episode 520:\n",
      "Learner 0\tLast reward:   242\tAverage reward: 236.43\n",
      "Learner 1\tLast reward:   270\tAverage reward: 163.61\n",
      "Episode 540:\n",
      "Learner 0\tLast reward:   278\tAverage reward: 242.47\n",
      "Learner 1\tLast reward:   175\tAverage reward: 171.32\n",
      "Episode 560:\n",
      "Learner 0\tLast reward:   195\tAverage reward: 249.70\n",
      "Learner 1\tLast reward:   230\tAverage reward: 170.87\n",
      "Episode 580:\n",
      "Learner 0\tLast reward:   299\tAverage reward: 251.09\n",
      "Learner 1\tLast reward:   149\tAverage reward: 170.92\n",
      "Episode 600:\n",
      "Learner 0\tLast reward:   223\tAverage reward: 250.91\n",
      "Learner 1\tLast reward:   146\tAverage reward: 169.81\n",
      "Episode 620:\n",
      "Learner 0\tLast reward:   230\tAverage reward: 250.14\n",
      "Learner 1\tLast reward:   259\tAverage reward: 182.63\n",
      "Episode 640:\n",
      "Learner 0\tLast reward:   312\tAverage reward: 259.62\n",
      "Learner 1\tLast reward:   208\tAverage reward: 182.05\n",
      "Episode 660:\n",
      "Learner 0\tLast reward:   281\tAverage reward: 266.91\n",
      "Learner 1\tLast reward:   177\tAverage reward: 182.71\n",
      "Episode 680:\n",
      "Learner 0\tLast reward:   335\tAverage reward: 278.16\n",
      "Learner 1\tLast reward:   136\tAverage reward: 181.78\n",
      "Episode 700:\n",
      "Learner 0\tLast reward:   232\tAverage reward: 277.05\n",
      "Learner 1\tLast reward:   166\tAverage reward: 188.42\n",
      "Episode 720:\n",
      "Learner 0\tLast reward:   240\tAverage reward: 265.72\n",
      "Learner 1\tLast reward:   212\tAverage reward: 194.50\n",
      "Episode 740:\n",
      "Learner 0\tLast reward:   317\tAverage reward: 267.77\n",
      "Learner 1\tLast reward:   204\tAverage reward: 200.48\n",
      "Episode 760:\n",
      "Learner 0\tLast reward:   438\tAverage reward: 277.31\n",
      "Learner 1\tLast reward:   119\tAverage reward: 199.08\n",
      "Episode 780:\n",
      "Learner 0\tLast reward:   163\tAverage reward: 272.36\n",
      "Learner 1\tLast reward:   230\tAverage reward: 201.44\n",
      "Episode 800:\n",
      "Learner 0\tLast reward:   384\tAverage reward: 277.21\n",
      "Learner 1\tLast reward:   231\tAverage reward: 205.38\n",
      "Episode 820:\n",
      "Learner 0\tLast reward:   373\tAverage reward: 287.65\n",
      "Learner 1\tLast reward:   136\tAverage reward: 201.89\n",
      "Episode 840:\n",
      "Learner 0\tLast reward:   305\tAverage reward: 287.84\n",
      "Learner 1\tLast reward:   139\tAverage reward: 197.05\n",
      "Episode 860:\n",
      "Learner 0\tLast reward:   224\tAverage reward: 281.06\n",
      "Learner 1\tLast reward:   312\tAverage reward: 202.15\n",
      "Episode 880:\n",
      "Learner 0\tLast reward:   257\tAverage reward: 277.35\n",
      "Learner 1\tLast reward:   179\tAverage reward: 210.43\n",
      "Episode 900:\n",
      "Learner 0\tLast reward:   142\tAverage reward: 271.32\n",
      "Learner 1\tLast reward:   271\tAverage reward: 212.78\n",
      "Episode 920:\n",
      "Learner 0\tLast reward:   307\tAverage reward: 268.15\n",
      "Learner 1\tLast reward:   230\tAverage reward: 216.53\n",
      "Episode 940:\n",
      "Learner 0\tLast reward:   241\tAverage reward: 267.31\n",
      "Learner 1\tLast reward:   319\tAverage reward: 219.49\n",
      "Episode 960:\n",
      "Learner 0\tLast reward:   293\tAverage reward: 255.40\n",
      "Learner 1\tLast reward:   224\tAverage reward: 235.74\n",
      "Episode 980:\n",
      "Learner 0\tLast reward:    72\tAverage reward: 245.28\n",
      "Learner 1\tLast reward:   481\tAverage reward: 254.07\n",
      "Episode 1000:\n",
      "Learner 0\tLast reward:   109\tAverage reward: 242.52\n",
      "Learner 1\tLast reward:   361\tAverage reward: 266.15\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from itertools import count\n",
    "\n",
    "from env import GatheringEnv\n",
    "from model import *    # Use the Policy and Rdn_policy defined in model.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "\n",
    "# We remove the argparse code and replace with hard parameters\n",
    "gamma = 0.99\n",
    "seed = 543\n",
    "render=False\n",
    "log_interval=20\n",
    "target_reward = 500\n",
    "\n",
    "# There will be 4 agents - 2 learning agents, 2 static agents\n",
    "num_learners = 2\n",
    "num_statics = 2\n",
    "num_agents = num_learners+num_statics  # just the sum of the two\n",
    "\n",
    "# Data structure for agents (learning and static)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "rewards = []\n",
    "\n",
    "# Data structure for training\n",
    "optimizers = []\n",
    "\n",
    "# Start the Gathering environment\n",
    "env = GatheringEnv(n_agents=num_agents, map_name='default')\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Initialize learner agents, then load static agents\n",
    "for i in range(num_learners):\n",
    "    print(\"Learner agent {}\".format(i+1))\n",
    "    agents.append(Policy(env.state_size, i+1))  # No weights loaded for learning agent\n",
    "    optimizers.append(optim.Adam(agents[i].parameters(), lr=1e-3))  # set up optimizer\n",
    "\n",
    "for i in range(num_learners, num_agents):\n",
    "    print(\"Load static agent {}\".format(i+1))\n",
    "    agents.append(Policy(env.state_size, i+1))\n",
    "    agents[i].load_weights()         # load weight for static agent\n",
    "    \n",
    "# Initialize all agent data\n",
    "for i in range(num_agents):\n",
    "    actions = [0 for i in range(num_agents)]\n",
    "    tags = [0 for i in range(num_agents)]\n",
    "    rewards = [0 for i in range(num_agents)]\n",
    "\n",
    "    \n",
    "# This is the task list to finish a game episode\n",
    "def finish_episode():\n",
    "    \"\"\" \n",
    "    Based on REINFORCE, policy gradient is calculated at the end of an episode.\n",
    "    It is then used to update the Policy's weights\n",
    "    \"\"\"\n",
    "    \n",
    "    # Our code will perform REINFORCE on each learning agent independently. \n",
    "    # Reward for each time step is stored in the list policy.rewards[] --> r(t)\n",
    "    \n",
    "    for i in range(num_learners):\n",
    "        # print(\"REINFORCE agent {}\".format(i+1))\n",
    "        R = 0  # noqa\n",
    "        rewards = []\n",
    "        for r in agents[i].rewards[::-1]:\n",
    "            R = r + gamma * R  # noqa\n",
    "            rewards.insert(0, R)\n",
    "        rewards = torch.Tensor(rewards)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + np.finfo(np.float32).eps)\n",
    "    \n",
    "        # Calculate policy gradient Σ_t[r(t) ∇_θ log(π_θ(s_t,a_t))\n",
    "        for action, r in zip(agents[i].saved_actions, rewards):\n",
    "            action.reinforce(r)     # Note that action.reinforce has been deprecated since torch V0.3\n",
    "        optimizers[i].zero_grad()\n",
    "        autograd.backward(agents[i].saved_actions, [None for _ in agents[i].saved_actions])\n",
    "        optimizers[i].step()\n",
    "    \n",
    "        del agents[i].rewards[:]\n",
    "        del agents[i].saved_actions[:]\n",
    "\n",
    "\n",
    "# Keep track of rewards learned by learners\n",
    "episode_reward = [0 for i in range(num_learners)]   # reward for an episode\n",
    "running_reward = [0 for i in range(num_learners)]   # running average\n",
    "best_reward = [0 for i in range(num_learners)]    # best running average (for storing best_model)\n",
    "\n",
    "\n",
    "for i_episode in range(1,2001):   # For each game episode\n",
    "    \n",
    "    # Some basic initialization\n",
    "    state = env.reset()\n",
    "    for i in range(num_learners):\n",
    "        episode_reward[i] = 0   # initialize episode rewards for learners\n",
    "    \n",
    "    for t in range(2001):  # Don't infinite loop while learning\n",
    "        \n",
    "        # 1. learning and static agents select their action\n",
    "        for i in range(num_agents):\n",
    "            actions[i] = agents[i].select_action(state[i])\n",
    "            if actions[i] is 6:\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "       \n",
    "        # 2. environment accepts action from learning and static agents and \n",
    "        # doles out next state, reward and if the episode is done\n",
    "        state_n, reward_n, done_n, _ = env.step(actions)\n",
    "        \n",
    "        state = state_n    # Go to next state\n",
    "        done = done_n[0]   # All agents have the same value for done_n\n",
    "        \n",
    "        if render:   # render learning if set to True\n",
    "            env.render()\n",
    "            \n",
    "        # For learner agents only, generate reward statistics and stack for REINFORCE\n",
    "        for i in range(num_learners):\n",
    "            agents[i].rewards.append(reward_n[i])  # Stack rewards (for REINFORCE)\n",
    "            episode_reward[i] += reward_n[i]   # accumulate episode reward \n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Update reward statistics for learners\n",
    "    for i in range(num_learners):\n",
    "        if running_reward[i] is None:\n",
    "            running_reward[i] = episode_reward[i]\n",
    "        running_reward[i] = running_reward[i] * 0.99 + episode_reward[i] * 0.01\n",
    "    \n",
    "    finish_episode()    # Finish up game episode\n",
    "        \n",
    "    if i_episode % log_interval == 0:\n",
    "        print('Episode {}:'.format(i_episode))\n",
    "        for i in range(num_learners):\n",
    "            # Display reward stats for learners\n",
    "            print('Learner {}\\tLast reward: {:5d}\\tAverage reward: {:.2f}'.format(\n",
    "            i, episode_reward[i], running_reward[i]))\n",
    "            \n",
    "            # Only save NN weights if running_reward is better than best_reward\n",
    "            if best_reward[i]is None:\n",
    "                best_reward[i] = running_reward[i]\n",
    "                agents[i].save_weights()   # Save NN weights for learner if this is the first save\n",
    "            else:\n",
    "                if running_reward[i] > best_reward[i]:\n",
    "                    agents[i].save_weights()   # Save NN weights for learner only if it performs better\n",
    "        \n",
    "env.close()  # Close the rendering window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play - 2 Newly Trained PG1 vs Trained PG3 va Rdn4\n",
    "\n",
    "We now play the 2 newly trained PG agents against the 1 previously-trained PG agents and a random agent\n",
    "    \n",
    "These newly trained agents (Agent 1 and 2) are super aggressive.\n",
    "\n",
    "Agent1 aggressiveness is 0.24  \n",
    "Agent1 reward is 107  \n",
    "Agent2 aggressiveness is 0.27  \n",
    "Agent2 reward is 195  \n",
    "Agent3 aggressiveness is 0.13  \n",
    "Agent3 reward is 17  \n",
    "Agent4 aggressiveness is 0.13  \n",
    "Agent4 reward is 0  \n",
    "\n",
    "They seem to have learned the following techniques:\n",
    "* Fire to the right to clear the path of other agents\n",
    "* Get to the food cluster and munch in a loop \n",
    "* Fire laser repeatedly to the left when they are facing left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load agent 0\n",
      "Load agent 1\n",
      "Load agent 2\n",
      "Load agent 3\n",
      "[4, 4, 5, 2]\n",
      "[0, 2, 6, 7]\n",
      "[0, 6, 6, 3]\n",
      "[1, 6, 0, 3]\n",
      "[0, 4, 2, 0]\n",
      "[6, 6, 2, 6]\n",
      "[0, 1, 0, 6]\n",
      "[4, 1, 0, 1]\n",
      "[4, 1, 0, 6]\n",
      "[0, 1, 5, 2]\n",
      "Agent1 aggressiveness is 0.30\n",
      "Agent1 reward is 30\n",
      "Agent2 aggressiveness is 0.15\n",
      "Agent2 reward is 0\n",
      "Agent3 aggressiveness is 0.18\n",
      "Agent3 reward is 0\n",
      "Agent4 aggressiveness is 0.15\n",
      "Agent4 reward is 0\n"
     ]
    }
   ],
   "source": [
    "from model import *    # Use the Policy and Rdn_policy defined in model.py\n",
    "\n",
    "# There will be 4 agents - 3 AI agents, 1 random agent\n",
    "num_ai_agents = 3\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "ai_agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "rewards = []\n",
    "\n",
    "env = GatheringEnv(n_agents=num_agents, map_name='default')\n",
    "\n",
    "# Env API is similar to that of OpenAI Gym\n",
    "state_n = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Load AI agents with trained weights\n",
    "for i in range(num_ai_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Policy(env.state_size, i+1))\n",
    "    ai_agents[i].load_weights()\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Rdn_Policy())\n",
    "\n",
    "# Initialize AI and random agent data\n",
    "for i in range(num_agents):\n",
    "    actions = [0 for i in range(num_agents)]\n",
    "    tags = [0 for i in range(num_agents)]\n",
    "    rewards = [0 for i in range(num_agents)]\n",
    "\n",
    "n_steps = 100\n",
    "\n",
    "# Render for n_steps steps\n",
    "for step in range(n_steps):\n",
    "    # Load AI agent with trained weights\n",
    "    for i in range(num_agents):\n",
    "        actions[i] = ai_agents[i].select_action(state_n[i])\n",
    "        if actions[i] is 6:\n",
    "            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print (actions)    \n",
    "            \n",
    "    state_n, reward_n, done_n, info_n = env.step(actions)\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        rewards[i] += reward_n[i]    # Accumulate rewards for each agent\n",
    "        \n",
    "    if any(done_n):\n",
    "        break\n",
    "    env.render()\n",
    "    time.sleep(1/30)  # Change speed of video rendering\n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "\n",
    "# Print out statistics of all agents\n",
    "for i in range(num_agents):\n",
    "    print (\"Agent{} aggressiveness is {:.2f}\".format(i+1, tags[i]/n_steps))\n",
    "    print (\"Agent{} reward is {:d}\".format(i+1, rewards[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2 3 4]\n",
      "  [1 2 3 4]\n",
      "  [1 2 3 4]]]\n",
      "[[[1 2 3 4]\n",
      "  [0 0 0 0]\n",
      "  [1 2 3 4]]]\n",
      "[[[1 2 0 4]\n",
      "  [0 0 0 0]\n",
      "  [1 2 0 4]]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1,1,1]]\n",
    "b = [[2,2,2]]\n",
    "c = [[3,3,3]]\n",
    "d = [[4,4,4]]\n",
    "\n",
    "full_state = np.stack([a,b,c,d], axis=-1)\n",
    "print (full_state)\n",
    "\n",
    "full_state[:,1,:]=0\n",
    "print (full_state)\n",
    "\n",
    "full_state[:,:,2]=0\n",
    "print (full_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring \"Getting Stuck\" Problem\n",
    "\n",
    "In the scenario where we put 3 AI agents (loaded with the same policy network), they have a tendency to get stuck. As witnessed in the scenario below.\n",
    "\n",
    "We believe this is because they have been originally trained against a single random agent, and therefore does not know how to avoid each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[(35, 25), (35, 26), (35, 27)]\n",
      "[2, 1, 0]\n",
      "(71, 51)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 800)\n",
      "Agent 1's Observation Space:\n",
      "Agent 1's Orientation: DOWN\n",
      "Agent 1's Action: UP\n",
      "Agent 1's Location: 35,25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 2's Observation Space:\n",
      "Agent 2's Orientation: RIGHT\n",
      "Agent 2's Action: RIGHT\n",
      "Agent 2's Location: 35,26\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 3's Observation Space:\n",
      "Agent 3's Orientation: UP\n",
      "Agent 3's Action: UP\n",
      "Agent 3's Location: 35,27\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAE5CAYAAACNoRQSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAADytJREFUeJzt3WuM7Hddx/HP1x4qUggUMQhtw8UQEjRRmhPCTUIowVIJVUNMiRcuJg1RFIyENCEhxGd4IV5CMBVQVCKNBZQQEFBJjA+onJYCvYAULNBabmIK6gOofH2wU1i2s2e/JTuXs/t6JZMzO/ObOb/59T+77/7//51T3R0AAE7v+zY9AQCAM4FoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMDAiVU8aVX5mHEA4Ezxle7+oYMG2dMEABx3n50MEk0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMCAaAIAGBBNAAADo2iqqour6pNVdUtVXbHqSQEAbJsDo6mqzkry+iTPTvK4JM+vqsetemIAANtksqfpCUlu6e7PdPc3krwtyaWrnRYAwHaZRNN5ST6/6+vbFrd9l6q6vKpOVdWpw5ocAMC2OHFYT9TdVya5Mkmqqg/reQEAtsFkT9PtSS7Y9fX5i9sAAI6NSTR9OMljqupRVXV2ksuSvGu10wIA2C4HHp7r7ruq6qVJ3pfkrCRv7u4bVz4zAIAtUt2Hf/qRc5oAgDPItd198qBBPhEcAGBANAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMCAaAIAGBBNAAADogkAYEA0AQAMiCYAgAHRBAAwIJoAAAZEEwDAgGgCABgQTQAAA6IJAGBANAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMCAaAIAGBBNAAADogkAYEA0AQAMiCYAgAHRBAAwIJoAAAZEEwDAwIHRVFUXVNUHq+qmqrqxql62jokBAGyTE4MxdyX5re6+rqoekOTaqvpAd9+04rkBAGyNA/c0dfcd3X3d4vrXk9yc5LxVTwwAYJvcq3OaquqRSR6f5JpVTAYAYFtNDs8lSarq/knenuTl3f21JfdfnuTyQ5wbAMDWqO4+eFDVfZK8O8n7uvt1g/EHPykAwHa4trtPHjRo8ttzleRNSW6eBBMAwFE0OafpKUl+Kckzqur6xeWSFc8LAGCrHHhOU3f/S5Jaw1wAALaWTwQHABgQTQAAA6IJAGBANAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYOPATwbmnyT9yfJh2/vk/AGCT7GkCABgQTQAAA6IJAGBANAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMCAaAIAGBBNAAADogkAYEA0AQAMiCYAgAHRBAAwIJoAAAZEEwDAgGgCABgQTQAAA6IJAGDgxKYncBi6e9NTWKl1v76qWuvfBwBnAnuaAAAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABsbRVFVnVdVHqurdq5wQAMA2ujd7ml6W5OZVTQQAYJuNoqmqzk/y00neuNrpAABsp+mepj9I8sok39pvQFVdXlWnqurUocwMAGCLHBhNVfWcJF/q7mtPN667r+zuk9198tBmBwCwJSZ7mp6S5LlVdWuStyV5RlX91UpnBQCwZaq754Ornp7kFd39nAPGzZ/0ENyb18DBqmrTUwCAdbp2cqTM5zQBAAzcqz1N4ye1p+mMZk8TAMeMPU0AAIdFNAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAMnNj2Bw3DUP4xx3R/euc6/76j/twPg6LCnCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMCAaAIAGBBNAAADogkAYEA0AQAMiCYAgAHRBAAwIJoAAAZEEwDAgGgCABgQTQAAA6IJAGBANAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAgRObnsBh6O5NT+FIqapNTwEAto49TQAAA6IJAGBANAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAOiCQBgYBRNVfWgqrq6qj5RVTdX1ZNWPTEAgG0y/bfn/jDJ33f386rq7CT3W+GcAAC2zoHRVFUPTPK0JC9Mku7+RpJvrHZaAADbZXJ47lFJvpzkz6rqI1X1xqo6Z++gqrq8qk5V1alDnyUAwIZNoulEkguTvKG7H5/kf5JcsXdQd1/Z3Se7++QhzxEAYOMm0XRbktu6+5rF11dnJ6IAAI6NA6Opu7+Q5PNV9djFTRcluWmlswIA2DLT35779SRvXfzm3GeSvGh1UwIA2D6jaOru65M4VwkAOLZ8IjgAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABqafCL7Vqmqtf193r/XvW/frAwDuyZ4mAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMCAaAIAGBBNAAADogkAYEA0AQAMiCYAgAHRBAAwIJoAAAZEEwDAgGgCABgQTQAAA6IJAGBANAEADIgmAIAB0QQAMCCaAAAGTmx6Ameiqtr0FACANbOnCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMCAaAIAGBBNAAADogkAYEA0AQAMjKKpqn6zqm6sqhuq6q+r6r6rnhgAwDY5MJqq6rwkv5HkZHf/WJKzkly26okBAGyT6eG5E0l+oKpOJLlfkv9Y3ZQAALbPgdHU3bcn+b0kn0tyR5I7u/v9e8dV1eVVdaqqTh3+NAEANmtyeO7cJJcmeVSShyc5p6p+ce+47r6yu09298nDnyYAwGZNDs89M8m/d/eXu/ubSd6R5MmrnRYAwHaZRNPnkjyxqu5XVZXkoiQ3r3ZaAADbZXJO0zVJrk5yXZKPLx5z5YrnBQCwVaq7D/9Jqw7/SQEAVuPayTnZPhEcAGBANAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADAgmgAABkQTAMCAaAIAGBBNAAADogkAYEA0AQAMiCYAgAHRBAAwIJoAAAZEEwDAgGgCABgQTQAAA6IJAGBANAEADIgmAIAB0QQAMCCaAAAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAAdEEADBwYkXP+5Ukn/0eHveQxWP5DmuynHVZzrosZ13uyZosZ12WO+rr8ojJoOruVU9krKpOdffJTc9jm1iT5azLctZlOetyT9ZkOeuynHXZ4fAcAMCAaAIAGNi2aLpy0xPYQtZkOeuynHVZzrrckzVZzrosZ12yZec0AQBsq23b0wQAsJVEEwDAwNqjqaourqpPVtUtVXXFkvu/v6quWtx/TVU9ct1zXLequqCqPlhVN1XVjVX1siVjnl5Vd1bV9YvLqzcx13Wrqlur6uOL13xqyf1VVX+02F4+VlUXbmKe61RVj921HVxfVV+rqpfvGXMstpeqenNVfamqbth124Or6gNV9anFn+fu89gXLMZ8qqpesL5Zr9Y+a/K7VfWJxXvknVX1oH0ee9r325lsn3V5TVXdvut9csk+jz3tz60z2T7rctWuNbm1qq7f57FHdnvZV3ev7ZLkrCSfTvLoJGcn+WiSx+0Z86tJ/mRx/bIkV61zjpu4JHlYkgsX1x+Q5N+WrMvTk7x703PdwNrcmuQhp7n/kiTvTVJJnpjkmk3Pec3rc1aSLyR5xJ7bj8X2kuRpSS5McsOu234nyRWL61ckee2Sxz04yWcWf567uH7upl/PCtfkWUlOLK6/dtmaLO477fvtTL7ssy6vSfKKAx534M+tM/mybF323P/7SV593LaX/S7r3tP0hCS3dPdnuvsbSd6W5NI9Yy5N8pbF9auTXFRVtcY5rl1339Hd1y2ufz3JzUnO2+yszhiXJvmL3vGhJA+qqodtelJrdFGST3f39/IJ/Ge87v7nJF/dc/Pu7yFvSfIzSx76U0k+0N1f7e7/SvKBJBevbKJrtGxNuvv93X3X4ssPJTl/7RPbsH22lYnJz60z1unWZfGz9+eT/PVaJ7XF1h1N5yX5/K6vb8s94+DbYxZv8juT/OBaZrcFFocjH5/kmiV3P6mqPlpV762qH13rxDank7y/qq6tqsuX3D/Zpo6yy7L/N7TjuL0kyUO7+47F9S8keeiSMcd5u3lxdvbOLnPQ++0oeunisOWb9zmUe5y3lZ9M8sXu/tQ+9x+77cWJ4Fukqu6f5O1JXt7dX9tz93XZOQTz40n+OMnfrnt+G/LU7r4wybOT/FpVPW3TE9oWVXV2kucm+Zsldx/X7eW79M4xBJ+rslBVr0pyV5K37jPkuL3f3pDkR5L8RJI7snMoiu94fk6/l+m4bS9rj6bbk1yw6+vzF7ctHVNVJ5I8MMl/rmV2G1RV98lOML21u9+x9/7u/lp3//fi+nuS3KeqHrLmaa5dd9+++PNLSd6ZnV3lu022qaPq2Umu6+4v7r3juG4vC1+8+xDt4s8vLRlz7Labqnphkuck+YVFTN7D4P12pHT3F7v7/7r7W0n+NMtf77HbVpJv//z9uSRX7TfmuG0vyfqj6cNJHlNVj1r8X/JlSd61Z8y7ktz9myzPS/JP+73Bj4rFceM3Jbm5u1+3z5gfvvvcrqp6Qnb+2x3pmKyqc6rqAXdfz87JrDfsGfauJL+8+C26Jya5c9ehmaNu3/8LPI7byy67v4e8IMnfLRnzviTPqqpzF4dknrW47UiqqouTvDLJc7v7f/cZM3m/HSl7zn/82Sx/vZOfW0fRM5N8ortvW3bncdxekqz3t+cW7XNJdn477NNJXrW47bez82ZOkvtm53DDLUn+NcmjN322/BrW5KnZOYTwsSTXLy6XJHlJkpcsxrw0yY3Z+c2NDyV58qbnvYZ1efTi9X508drv3l52r0slef1ie/p4kpObnvea1uac7ETQA3fdduy2l+xE4x1Jvpmdc01+JTvnQP5jkk8l+YckD16MPZnkjbse++LF95lbkrxo069lxWtyS3bOy7n7+8vdv6H88CTvWVxf+n47Kpd91uUvF983PpadEHrY3nVZfH2Pn1tH5bJsXRa3//nd3092jT0228t+F/+MCgDAgBPBAQAGRBMAwIBoAgAYEE0AAAOiCQBgQDQBAAyIJgCAgf8Hx2vXrSm9KZ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "action=['UP','RIGHT','DOWN','LEFT']\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "print(env.state_size)\n",
    "print (env.agents)\n",
    "print (env.orientations)\n",
    "\n",
    "game_space = env.food + env.walls\n",
    "print(game_space.shape)\n",
    "\n",
    "game_space[env.agents[0]]=10\n",
    "plt.imshow(game_space.T)\n",
    "plt.show()\n",
    "\n",
    "print (state_n.shape)\n",
    "\n",
    "print (\"Agent 1's Observation Space:\")\n",
    "print (\"Agent 1's Orientation: {}\".format(action[env.orientations[0]]))\n",
    "print (\"Agent 1's Action: {}\".format(action[actions[0]]))\n",
    "print (\"Agent 1's Location: {},{}\".format(env.agents[0][0], env.agents[0][1]))\n",
    "\n",
    "observation1 = state_n[0].reshape(10,20,4)\n",
    "plt.imshow(observation1[:, :, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 2])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 3])\n",
    "plt.show()\n",
    "\n",
    "game_space[env.agents[0]]=0\n",
    "game_space[env.agents[1]]=10\n",
    "plt.imshow(game_space.T)\n",
    "plt.show()\n",
    "\n",
    "print (\"Agent 2's Observation Space:\")\n",
    "print (\"Agent 2's Orientation: {}\".format(action[env.orientations[1]]))\n",
    "print (\"Agent 2's Action: {}\".format(action[actions[1]]))\n",
    "print (\"Agent 2's Location: {},{}\".format(env.agents[1][0], env.agents[1][1]))\n",
    "\n",
    "observation1 = state_n[1].reshape(10,20,4)\n",
    "plt.imshow(observation1[:, :, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 2])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 3])\n",
    "plt.show()\n",
    "\n",
    "game_space[env.agents[0]]=0\n",
    "game_space[env.agents[1]]=0\n",
    "game_space[env.agents[2]]=10\n",
    "plt.imshow(game_space.T)\n",
    "plt.show()\n",
    "\n",
    "print (\"Agent 3's Observation Space:\")\n",
    "print (\"Agent 3's Orientation: {}\".format(action[env.orientations[2]]))\n",
    "print (\"Agent 3's Action: {}\".format(action[actions[2]]))\n",
    "print (\"Agent 3's Location: {},{}\".format(env.agents[2][0], env.agents[2][1]))\n",
    "\n",
    "observation1 = state_n[2].reshape(10,20,4)\n",
    "plt.imshow(observation1[:, :, 0])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 2])\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(observation1[:, :, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1\n",
      "1 0\n",
      "0 1\n",
      "-1 0\n"
     ]
    }
   ],
   "source": [
    "movement_n = [\n",
    "                (0, -1),  # up/forward\n",
    "                (1, 0),   # right\n",
    "                (0, 1),   # down/backward\n",
    "                (-1, 0),  # left\n",
    "            ]\n",
    "for move in movement_n:\n",
    "    x, y = move\n",
    "    print (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 0, 0], [10, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "action1 = [5, 0, 0]\n",
    "action2 = [10, 0, 0]\n",
    "\n",
    "print([action1,action2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 0, 0]]\n",
      "[[5, 0, 0], [10, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "action1 = [5, 0, 0]\n",
    "action2 = [10, 0, 0]\n",
    "action = []\n",
    "\n",
    "action.append(action1)\n",
    "print (action)\n",
    "action.append(action2)\n",
    "print (action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 0, 10, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(action1+action2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"agent-4-model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Multiple NNs - 1\n",
    "\n",
    "This is the most basic framework for training multiple NN. Here the NNs are totally separate, and each NN learns independently with separate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 633.7586669921875 777.9849853515625\n",
      "1 585.9645385742188 719.013427734375\n",
      "2 544.7007446289062 667.6548461914062\n",
      "3 508.760986328125 622.6159057617188\n",
      "4 477.0133972167969 582.5451049804688\n",
      "5 448.34637451171875 546.59423828125\n",
      "6 422.60357666015625 514.1270751953125\n",
      "7 399.3191833496094 484.2102355957031\n",
      "8 377.7106018066406 456.41351318359375\n",
      "9 357.5779113769531 430.5800476074219\n",
      "10 338.8116455078125 406.2713317871094\n",
      "11 321.2728271484375 383.4058532714844\n",
      "12 304.8344421386719 361.7463684082031\n",
      "13 289.3735656738281 341.2002258300781\n",
      "14 274.7208251953125 321.6092224121094\n",
      "15 260.80517578125 302.99151611328125\n",
      "16 247.5433349609375 285.3048095703125\n",
      "17 234.88916015625 268.4383544921875\n",
      "18 222.8232421875 252.4706573486328\n",
      "19 211.3445587158203 237.30398559570312\n",
      "20 200.42489624023438 222.90956115722656\n",
      "21 189.98658752441406 209.28466796875\n",
      "22 180.0203857421875 196.42300415039062\n",
      "23 170.4871063232422 184.2354278564453\n",
      "24 161.40802001953125 172.69847106933594\n",
      "25 152.75747680664062 161.8121337890625\n",
      "26 144.45835876464844 151.52944946289062\n",
      "27 136.53176879882812 141.85011291503906\n",
      "28 129.01296997070312 132.76370239257812\n",
      "29 121.86719512939453 124.21617126464844\n",
      "30 115.09986114501953 116.19549560546875\n",
      "31 108.69680786132812 108.63775634765625\n",
      "32 102.61744689941406 101.57140350341797\n",
      "33 96.8534927368164 94.96392822265625\n",
      "34 91.39212799072266 88.78449249267578\n",
      "35 86.21489715576172 83.01321411132812\n",
      "36 81.32596588134766 77.61537170410156\n",
      "37 76.70802307128906 72.58414459228516\n",
      "38 72.34907531738281 67.89225769042969\n",
      "39 68.21883392333984 63.510684967041016\n",
      "40 64.32057189941406 59.42585754394531\n",
      "41 60.6464958190918 55.623077392578125\n",
      "42 57.18157958984375 52.07798767089844\n",
      "43 53.91169738769531 48.76103591918945\n",
      "44 50.827388763427734 45.67061233520508\n",
      "45 47.919795989990234 42.79386520385742\n",
      "46 45.18292999267578 40.11269760131836\n",
      "47 42.60619354248047 37.60966110229492\n",
      "48 40.17644119262695 35.277366638183594\n",
      "49 37.87571334838867 33.09794616699219\n",
      "50 35.70901107788086 31.06535530090332\n",
      "51 33.66846466064453 29.172142028808594\n",
      "52 31.750089645385742 27.408321380615234\n",
      "53 29.945486068725586 25.7601261138916\n",
      "54 28.247739791870117 24.223356246948242\n",
      "55 26.649229049682617 22.78801918029785\n",
      "56 25.14325523376465 21.447757720947266\n",
      "57 23.725765228271484 20.197402954101562\n",
      "58 22.390094757080078 19.025901794433594\n",
      "59 21.133087158203125 17.928348541259766\n",
      "60 19.950651168823242 16.90071678161621\n",
      "61 18.83619499206543 15.939294815063477\n",
      "62 17.78476905822754 15.037617683410645\n",
      "63 16.79502296447754 14.193164825439453\n",
      "64 15.863211631774902 13.402617454528809\n",
      "65 14.98564624786377 12.66016674041748\n",
      "66 14.1588716506958 11.958776473999023\n",
      "67 13.38015365600586 11.300459861755371\n",
      "68 12.64546012878418 10.681907653808594\n",
      "69 11.952427864074707 10.099737167358398\n",
      "70 11.298766136169434 9.55229377746582\n",
      "71 10.682665824890137 9.038296699523926\n",
      "72 10.101279258728027 8.553746223449707\n",
      "73 9.553153991699219 8.097251892089844\n",
      "74 9.036242485046387 7.668891429901123\n",
      "75 8.547999382019043 7.265231609344482\n",
      "76 8.08761978149414 6.885161399841309\n",
      "77 7.652791500091553 6.52665376663208\n",
      "78 7.24267053604126 6.188652992248535\n",
      "79 6.85593843460083 5.8695855140686035\n",
      "80 6.490489482879639 5.568373680114746\n",
      "81 6.14531135559082 5.283956527709961\n",
      "82 5.8198747634887695 5.015618801116943\n",
      "83 5.512683868408203 4.761868476867676\n",
      "84 5.222095012664795 4.522360324859619\n",
      "85 4.9474687576293945 4.296086311340332\n",
      "86 4.688045024871826 4.082221031188965\n",
      "87 4.442887783050537 3.8800623416900635\n",
      "88 4.210991382598877 3.688647747039795\n",
      "89 3.991786241531372 3.507516622543335\n",
      "90 3.7850122451782227 3.3361191749572754\n",
      "91 3.5896072387695312 3.1738955974578857\n",
      "92 3.404794216156006 3.0200891494750977\n",
      "93 3.230118751525879 2.8741061687469482\n",
      "94 3.064807891845703 2.73581600189209\n",
      "95 2.9086031913757324 2.6047277450561523\n",
      "96 2.7609636783599854 2.4804561138153076\n",
      "97 2.6210925579071045 2.3627467155456543\n",
      "98 2.488778591156006 2.2510976791381836\n",
      "99 2.363396167755127 2.1451175212860107\n",
      "100 2.244758129119873 2.0444445610046387\n",
      "101 2.1324527263641357 1.9487963914871216\n",
      "102 2.0260109901428223 1.8580363988876343\n",
      "103 1.9251668453216553 1.7719093561172485\n",
      "104 1.8295948505401611 1.6900792121887207\n",
      "105 1.7390998601913452 1.612321138381958\n",
      "106 1.653510570526123 1.538383960723877\n",
      "107 1.5724724531173706 1.4681154489517212\n",
      "108 1.4956125020980835 1.4012141227722168\n",
      "109 1.4227485656738281 1.3376120328903198\n",
      "110 1.3535758256912231 1.2772045135498047\n",
      "111 1.2880131006240845 1.2196882963180542\n",
      "112 1.2258023023605347 1.1649556159973145\n",
      "113 1.1668624877929688 1.1128838062286377\n",
      "114 1.110817313194275 1.0633217096328735\n",
      "115 1.0576748847961426 1.0161348581314087\n",
      "116 1.0072567462921143 0.9712250232696533\n",
      "117 0.959345817565918 0.9285866618156433\n",
      "118 0.9138169884681702 0.8879677653312683\n",
      "119 0.8706119060516357 0.8492680788040161\n",
      "120 0.8296152949333191 0.8123883008956909\n",
      "121 0.7907662391662598 0.7772513031959534\n",
      "122 0.7537907958030701 0.7437712550163269\n",
      "123 0.7186583876609802 0.7118918299674988\n",
      "124 0.6852627396583557 0.6814432740211487\n",
      "125 0.653535783290863 0.6524534225463867\n",
      "126 0.6234205365180969 0.6247823238372803\n",
      "127 0.5947407484054565 0.5983905792236328\n",
      "128 0.5674702525138855 0.5732153058052063\n",
      "129 0.5415157079696655 0.549277126789093\n",
      "130 0.5168329477310181 0.5264354348182678\n",
      "131 0.49335408210754395 0.5046127438545227\n",
      "132 0.47103139758110046 0.4837754964828491\n",
      "133 0.4497635066509247 0.4638502597808838\n",
      "134 0.4295519292354584 0.44480374455451965\n",
      "135 0.41038721799850464 0.4266095757484436\n",
      "136 0.39214321970939636 0.4092005491256714\n",
      "137 0.37474897503852844 0.39258143305778503\n",
      "138 0.35818246006965637 0.3766668736934662\n",
      "139 0.342403382062912 0.3614474833011627\n",
      "140 0.327358603477478 0.3468937277793884\n",
      "141 0.3130284547805786 0.3329625427722931\n",
      "142 0.29934895038604736 0.3196388781070709\n",
      "143 0.28632113337516785 0.3069014251232147\n",
      "144 0.27389654517173767 0.2946995496749878\n",
      "145 0.26205042004585266 0.2830357253551483\n",
      "146 0.2507428228855133 0.2718634605407715\n",
      "147 0.23994669318199158 0.261160284280777\n",
      "148 0.22965236008167267 0.2509075999259949\n",
      "149 0.21982359886169434 0.24108760058879852\n",
      "150 0.21044224500656128 0.23167960345745087\n",
      "151 0.20148347318172455 0.22267018258571625\n",
      "152 0.1929289698600769 0.21403774619102478\n",
      "153 0.18476751446723938 0.2057693898677826\n",
      "154 0.17698787152767181 0.19784203171730042\n",
      "155 0.16953569650650024 0.1902397722005844\n",
      "156 0.16241581737995148 0.1829492598772049\n",
      "157 0.15561611950397491 0.17595870792865753\n",
      "158 0.14912116527557373 0.1692584902048111\n",
      "159 0.14291389286518097 0.16283604502677917\n",
      "160 0.13697725534439087 0.1566792130470276\n",
      "161 0.13130320608615875 0.1507638692855835\n",
      "162 0.12587669491767883 0.14509417116641998\n",
      "163 0.12068527191877365 0.13964730501174927\n",
      "164 0.11571858078241348 0.13441982865333557\n",
      "165 0.11097241193056107 0.12940338253974915\n",
      "166 0.10643689334392548 0.12459143251180649\n",
      "167 0.10208863019943237 0.11996836215257645\n",
      "168 0.09792460501194 0.11552984267473221\n",
      "169 0.09394043684005737 0.11126837134361267\n",
      "170 0.09012718498706818 0.10717757046222687\n",
      "171 0.08647903054952621 0.10324610024690628\n",
      "172 0.08298896998167038 0.09946655482053757\n",
      "173 0.07964614033699036 0.09583886712789536\n",
      "174 0.07644350826740265 0.09235648065805435\n",
      "175 0.07337624579668045 0.08900744467973709\n",
      "176 0.07043889164924622 0.08578719198703766\n",
      "177 0.06762748211622238 0.08269507437944412\n",
      "178 0.06493151932954788 0.07972029596567154\n",
      "179 0.06234981492161751 0.07686162739992142\n",
      "180 0.05987391248345375 0.07411844283342361\n",
      "181 0.05750259757041931 0.07147271931171417\n",
      "182 0.05522720143198967 0.06893008202314377\n",
      "183 0.053047068417072296 0.06648540496826172\n",
      "184 0.050956882536411285 0.06413183361291885\n",
      "185 0.048954494297504425 0.061868008226156235\n",
      "186 0.047036342322826385 0.059690240770578384\n",
      "187 0.045193154364824295 0.057595472782850266\n",
      "188 0.043425947427749634 0.05557933449745178\n",
      "189 0.04173097386956215 0.053639691323041916\n",
      "190 0.04010593891143799 0.05177397280931473\n",
      "191 0.038547806441783905 0.04998030513525009\n",
      "192 0.037052419036626816 0.04825414717197418\n",
      "193 0.03561914339661598 0.046592675149440765\n",
      "194 0.03424237295985222 0.044990576803684235\n",
      "195 0.03292044997215271 0.04344901815056801\n",
      "196 0.031652580946683884 0.041963379830121994\n",
      "197 0.030435502529144287 0.04053198918700218\n",
      "198 0.02926701121032238 0.03915361315011978\n",
      "199 0.028144724667072296 0.03782832995057106\n",
      "200 0.027067547664046288 0.036553557962179184\n",
      "201 0.026036078110337257 0.035325076431035995\n",
      "202 0.025041108950972557 0.03413967043161392\n",
      "203 0.024086907505989075 0.03299706056714058\n",
      "204 0.023170437663793564 0.03189550340175629\n",
      "205 0.022291118279099464 0.030832834541797638\n",
      "206 0.021445931866765022 0.029808854684233665\n",
      "207 0.020633719861507416 0.028822816908359528\n",
      "208 0.01985309086740017 0.027870502322912216\n",
      "209 0.01910325698554516 0.02695123292505741\n",
      "210 0.018384071066975594 0.026064584031701088\n",
      "211 0.01769193820655346 0.025208594277501106\n",
      "212 0.01702648587524891 0.024383338168263435\n",
      "213 0.016386952251195908 0.0235870573669672\n",
      "214 0.015772510319948196 0.02281806245446205\n",
      "215 0.015182437375187874 0.02207581326365471\n",
      "216 0.014614763669669628 0.02135906182229519\n",
      "217 0.01406875066459179 0.020667342469096184\n",
      "218 0.013543856330215931 0.019999545067548752\n",
      "219 0.013039137236773968 0.01935475319623947\n",
      "220 0.012554136104881763 0.018732139840722084\n",
      "221 0.012087944895029068 0.018130991607904434\n",
      "222 0.011639071628451347 0.01755022257566452\n",
      "223 0.01120760291814804 0.016989201307296753\n",
      "224 0.01079269777983427 0.016446979716420174\n",
      "225 0.010393472388386726 0.015923231840133667\n",
      "226 0.010009787045419216 0.01541732158511877\n",
      "227 0.00964035838842392 0.014928452670574188\n",
      "228 0.00928527768701315 0.014456070959568024\n",
      "229 0.008943294174969196 0.01399964839220047\n",
      "230 0.008614485152065754 0.013558262959122658\n",
      "231 0.00829820055514574 0.013131776824593544\n",
      "232 0.00799424946308136 0.012719337828457355\n",
      "233 0.007701166905462742 0.012320670299232006\n",
      "234 0.00741917360574007 0.011935548856854439\n",
      "235 0.007147827185690403 0.011562884785234928\n",
      "236 0.006886577699333429 0.011202448979020119\n",
      "237 0.006635255645960569 0.01085403561592102\n",
      "238 0.006393266376107931 0.010517035610973835\n",
      "239 0.006160243880003691 0.010191066190600395\n",
      "240 0.005935909226536751 0.00987562257796526\n",
      "241 0.005720310378819704 0.0095706507563591\n",
      "242 0.005512509029358625 0.009275573305785656\n",
      "243 0.005312527995556593 0.008990214206278324\n",
      "244 0.005120096728205681 0.00871401745826006\n",
      "245 0.004935006145387888 0.00844666175544262\n",
      "246 0.004756087902933359 0.008188039064407349\n",
      "247 0.0045839822851121426 0.007937817834317684\n",
      "248 0.0044185444712638855 0.007695607841014862\n",
      "249 0.004259160254150629 0.0074610901065170765\n",
      "250 0.004105547443032265 0.007234069053083658\n",
      "251 0.003957507666200399 0.007014339789748192\n",
      "252 0.0038149950560182333 0.006801630835980177\n",
      "253 0.003677709260955453 0.006595749873667955\n",
      "254 0.00354545540176332 0.006396509241312742\n",
      "255 0.0034180828370153904 0.00620346749201417\n",
      "256 0.003295553382486105 0.006016627885401249\n",
      "257 0.003177373204380274 0.005835704039782286\n",
      "258 0.003063464304432273 0.005660592578351498\n",
      "259 0.002953736111521721 0.005490776617079973\n",
      "260 0.0028481322806328535 0.005326370242983103\n",
      "261 0.0027462197467684746 0.005167194176465273\n",
      "262 0.0026480781380087137 0.005012822337448597\n",
      "263 0.0025534990709275007 0.004863359499722719\n",
      "264 0.002462384756654501 0.004718604031950235\n",
      "265 0.00237461575306952 0.00457822484895587\n",
      "266 0.0022900220938026905 0.004442320205271244\n",
      "267 0.0022084915544837713 0.004310640040785074\n",
      "268 0.002129915403202176 0.004182911012321711\n",
      "269 0.002054280135780573 0.004059178754687309\n",
      "270 0.00198135687969625 0.003939371556043625\n",
      "271 0.0019110414432361722 0.003823388833552599\n",
      "272 0.0018432574579492211 0.0037109239492565393\n",
      "273 0.001777924713678658 0.0036018879618495703\n",
      "274 0.001714904559776187 0.0034962021745741367\n",
      "275 0.0016542210942134261 0.003393850289285183\n",
      "276 0.0015957228606566787 0.0032945708371698856\n",
      "277 0.0015393473440781236 0.0031982669606804848\n",
      "278 0.0014849435538053513 0.003104917239397764\n",
      "279 0.0014324915828183293 0.0030144157353788614\n",
      "280 0.0013819194864481688 0.002926743822172284\n",
      "281 0.0013331949012354016 0.002841618377715349\n",
      "282 0.0012863186420872808 0.0027590622194111347\n",
      "283 0.0012410287745296955 0.0026790329720824957\n",
      "284 0.0011973630171269178 0.0026014172472059727\n",
      "285 0.0011552625801414251 0.0025261028204113245\n",
      "286 0.0011147186160087585 0.0024530519731342793\n",
      "287 0.0010756513802334666 0.0023821904323995113\n",
      "288 0.0010379132581874728 0.002313446719199419\n",
      "289 0.0010015025036409497 0.0022467647213488817\n",
      "290 0.0009665744728408754 0.002182080876082182\n",
      "291 0.0009328717715106905 0.0021193111315369606\n",
      "292 0.0009004037128761411 0.0020584152080118656\n",
      "293 0.0008690649992786348 0.001999329077079892\n",
      "294 0.000838840554933995 0.0019420174648985267\n",
      "295 0.0008097016252577305 0.0018864094745367765\n",
      "296 0.0007815523422323167 0.0018324323464185\n",
      "297 0.0007544402615167201 0.001780048361979425\n",
      "298 0.0007282429141923785 0.0017292018746957183\n",
      "299 0.0007030142587609589 0.0016798791475594044\n",
      "300 0.0006786404410377145 0.0016320203430950642\n",
      "301 0.0006551261176355183 0.0015855565434321761\n",
      "302 0.0006324578425846994 0.0015404729638248682\n",
      "303 0.0006105809006839991 0.0014966814778745174\n",
      "304 0.0005894590867683291 0.0014541788259521127\n",
      "305 0.0005690678954124451 0.0014129446353763342\n",
      "306 0.0005494229262694716 0.0013728908961638808\n",
      "307 0.0005304536898620427 0.0013340135337784886\n",
      "308 0.0005121544236317277 0.0012962876353412867\n",
      "309 0.0004944988759234548 0.0012596379965543747\n",
      "310 0.0004774383269250393 0.001224059727974236\n",
      "311 0.00046098779421299696 0.0011895033530890942\n",
      "312 0.00044512443128041923 0.0011559720151126385\n",
      "313 0.00042980880243703723 0.0011234127450734377\n",
      "314 0.00041501136729493737 0.001091824029572308\n",
      "315 0.0004007343668490648 0.001061126939021051\n",
      "316 0.00038696243427693844 0.0010313071543350816\n",
      "317 0.00037367024924606085 0.0010023486101999879\n",
      "318 0.00036084765451960266 0.0009742443216964602\n",
      "319 0.0003484554181341082 0.0009469302603974938\n",
      "320 0.0003365160955581814 0.000920402817428112\n",
      "321 0.00032496455241926014 0.0008946743328124285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 0.0003138418833259493 0.0008696551667526364\n",
      "323 0.00030308120767585933 0.0008453581249341369\n",
      "324 0.000292719341814518 0.0008217587019316852\n",
      "325 0.00028267898596823215 0.0007988351862877607\n",
      "326 0.0002730231499299407 0.0007765698246657848\n",
      "327 0.0002636894350871444 0.0007549366564489901\n",
      "328 0.00025467504747211933 0.000733919907361269\n",
      "329 0.00024596057482995093 0.0007134964689612389\n",
      "330 0.00023755818256177008 0.0006936698919162154\n",
      "331 0.00022944148804526776 0.0006744158454239368\n",
      "332 0.00022161488595884293 0.000655686657410115\n",
      "333 0.0002140512369805947 0.0006374967051669955\n",
      "334 0.00020675052655860782 0.000619823404122144\n",
      "335 0.00019969492859672755 0.0006026747869327664\n",
      "336 0.00019289761257823557 0.0005859834491275251\n",
      "337 0.0001863196084741503 0.0005697777960449457\n",
      "338 0.00017997513350564986 0.000554037862457335\n",
      "339 0.00017384483362548053 0.0005387343117035925\n",
      "340 0.00016791549569461495 0.0005238717421889305\n",
      "341 0.00016220459656324238 0.0005094282678328454\n",
      "342 0.0001566801656736061 0.0004953813040629029\n",
      "343 0.00015135249122977257 0.00048174362746067345\n",
      "344 0.00014620811271015555 0.00046847620978951454\n",
      "345 0.00014124053996056318 0.000455585919553414\n",
      "346 0.0001364418858429417 0.00044306181371212006\n",
      "347 0.00013180694077163935 0.00043089102837257087\n",
      "348 0.00012732944742310792 0.00041905519901774824\n",
      "349 0.00012300675734877586 0.000407563173212111\n",
      "350 0.00011883288971148431 0.0003963847120758146\n",
      "351 0.00011479743261588737 0.000385523570002988\n",
      "352 0.00011090460611740127 0.00037495512515306473\n",
      "353 0.00010714212112361565 0.00036469005863182247\n",
      "354 0.00010350839875172824 0.0003547165251802653\n",
      "355 9.999930625781417e-05 0.0003450181393418461\n",
      "356 9.661218791734427e-05 0.0003356008091941476\n",
      "357 9.333975322078913e-05 0.00032644023303873837\n",
      "358 9.017650154419243e-05 0.0003175430465489626\n",
      "359 8.712663111509755e-05 0.0003088658850174397\n",
      "360 8.417384378844872e-05 0.00030044763116165996\n",
      "361 8.132870425470173e-05 0.00029226599144749343\n",
      "362 7.857431774027646e-05 0.0002843060647137463\n",
      "363 7.591965550091118e-05 0.00027656659949570894\n",
      "364 7.335366535698995e-05 0.0002690354303922504\n",
      "365 7.087571430020034e-05 0.0002617223362904042\n",
      "366 6.848433258710429e-05 0.0002546163450460881\n",
      "367 6.617108010686934e-05 0.00024769542505964637\n",
      "368 6.393721560016274e-05 0.00024096903507597744\n",
      "369 6.17746845819056e-05 0.0002344295207876712\n",
      "370 5.968745972495526e-05 0.00022807616915088147\n",
      "371 5.767089533037506e-05 0.0002218924928456545\n",
      "372 5.572972077061422e-05 0.0002158842544304207\n",
      "373 5.385214899433777e-05 0.0002100395504385233\n",
      "374 5.2035557018825784e-05 0.00020436674822121859\n",
      "375 5.028097075410187e-05 0.00019883536151610315\n",
      "376 4.859006003243849e-05 0.00019346384215168655\n",
      "377 4.6952834964031354e-05 0.00018823753634933382\n",
      "378 4.537072163657285e-05 0.00018314838234800845\n",
      "379 4.384020940051414e-05 0.00017820269567891955\n",
      "380 4.236457607476041e-05 0.00017339922487735748\n",
      "381 4.093756069778465e-05 0.0001687170733930543\n",
      "382 3.956209548050538e-05 0.00016417106962762773\n",
      "383 3.82279722543899e-05 0.0001597520604263991\n",
      "384 3.694095357786864e-05 0.0001554458576720208\n",
      "385 3.5699540603673086e-05 0.0001512618619017303\n",
      "386 3.4500328183639795e-05 0.00014718942111358047\n",
      "387 3.333893619128503e-05 0.00014323482173494995\n",
      "388 3.221704173483886e-05 0.00013938324991613626\n",
      "389 3.113314232905395e-05 0.00013563709217123687\n",
      "390 3.0086772312643006e-05 0.00013200393004808575\n",
      "391 2.9075554266455583e-05 0.00012846224126406014\n",
      "392 2.8099248083890416e-05 0.0001250139030162245\n",
      "393 2.7153651899425313e-05 0.00012166246597189456\n",
      "394 2.624340049806051e-05 0.00011840106890304014\n",
      "395 2.536237116146367e-05 0.0001152229233412072\n",
      "396 2.4509394279448316e-05 0.00011214079859200865\n",
      "397 2.368646892136894e-05 0.00010914039012277499\n",
      "398 2.2892007109476253e-05 0.00010621899127727374\n",
      "399 2.2124344468466006e-05 0.00010337817366234958\n",
      "400 2.1381620172178373e-05 0.00010061957436846569\n",
      "401 2.0664019757532515e-05 9.79256074060686e-05\n",
      "402 1.9971079382230528e-05 9.53156704781577e-05\n",
      "403 1.930238795466721e-05 9.276942728320137e-05\n",
      "404 1.865610647655558e-05 9.029335342347622e-05\n",
      "405 1.803033592295833e-05 8.788557897787541e-05\n",
      "406 1.7427653801860288e-05 8.554590749554336e-05\n",
      "407 1.684269227553159e-05 8.326586248585954e-05\n",
      "408 1.6279676856356673e-05 8.104492007987574e-05\n",
      "409 1.573259760334622e-05 7.888846448622644e-05\n",
      "410 1.5205486306513194e-05 7.678180554648861e-05\n",
      "411 1.4695850950374734e-05 7.474375888705254e-05\n",
      "412 1.4205455045157578e-05 7.275892130564898e-05\n",
      "413 1.3729073543800041e-05 7.082383672241122e-05\n",
      "414 1.3268968359625433e-05 6.894024409120902e-05\n",
      "415 1.2825349585909862e-05 6.711315654683858e-05\n",
      "416 1.2395262274367269e-05 6.532648694701493e-05\n",
      "417 1.1981467650912236e-05 6.359320832416415e-05\n",
      "418 1.158110626420239e-05 6.190685235196725e-05\n",
      "419 1.119193166232435e-05 6.026391565683298e-05\n",
      "420 1.0818884220498148e-05 5.8665729739004746e-05\n",
      "421 1.0457049938850105e-05 5.711584526579827e-05\n",
      "422 1.0108487913385034e-05 5.5599273764528334e-05\n",
      "423 9.770531505637337e-06 5.412751852418296e-05\n",
      "424 9.442572263651527e-06 5.269551184028387e-05\n",
      "425 9.128555575443897e-06 5.130198042024858e-05\n",
      "426 8.822679774311837e-06 4.994301707483828e-05\n",
      "427 8.528335456503555e-06 4.862248169956729e-05\n",
      "428 8.243059710366651e-06 4.733981768367812e-05\n",
      "429 7.967297278810292e-06 4.608730159816332e-05\n",
      "430 7.701170034124516e-06 4.486984835239127e-05\n",
      "431 7.444221864716383e-06 4.368391091702506e-05\n",
      "432 7.195496891654329e-06 4.2527219193289056e-05\n",
      "433 6.95430480845971e-06 4.140824603382498e-05\n",
      "434 6.724339527863776e-06 4.031455682707019e-05\n",
      "435 6.5005374381144065e-06 3.9251150155905634e-05\n",
      "436 6.282686172198737e-06 3.82197140424978e-05\n",
      "437 6.072934411349706e-06 3.7213194445939735e-05\n",
      "438 5.8701166381069925e-06 3.623164593591355e-05\n",
      "439 5.675208740285598e-06 3.527700755512342e-05\n",
      "440 5.485384008352412e-06 3.4347780456300825e-05\n",
      "441 5.302856607158901e-06 3.344267315696925e-05\n",
      "442 5.1261326916574035e-06 3.256419222452678e-05\n",
      "443 4.955184067512164e-06 3.170751369907521e-05\n",
      "444 4.789402737515047e-06 3.087539516855031e-05\n",
      "445 4.6304626266646665e-06 3.0064806196605787e-05\n",
      "446 4.474949037103215e-06 2.9273405743879266e-05\n",
      "447 4.326625003159279e-06 2.8501832275651395e-05\n",
      "448 4.1826801862043794e-06 2.7756277631851844e-05\n",
      "449 4.04356796934735e-06 2.702634628803935e-05\n",
      "450 3.90815375794773e-06 2.6317136871512048e-05\n",
      "451 3.7783454445161624e-06 2.56279108725721e-05\n",
      "452 3.6521801121125463e-06 2.495669832569547e-05\n",
      "453 3.5302562082506483e-06 2.4300361474161036e-05\n",
      "454 3.4132610835513333e-06 2.366437911405228e-05\n",
      "455 3.2991106309054885e-06 2.3043925466481596e-05\n",
      "456 3.1899448913463857e-06 2.244096322101541e-05\n",
      "457 3.083354840782704e-06 2.1853997168364003e-05\n",
      "458 2.980809313157806e-06 2.128188862116076e-05\n",
      "459 2.8818901682825526e-06 2.0724253772641532e-05\n",
      "460 2.786561481116223e-06 2.0182316802674904e-05\n",
      "461 2.6933682875096565e-06 1.9655024516396224e-05\n",
      "462 2.6036416329588974e-06 1.9139721189276315e-05\n",
      "463 2.5175809241773095e-06 1.8638975234352984e-05\n",
      "464 2.433202098472975e-06 1.81523610081058e-05\n",
      "465 2.3527957182523096e-06 1.767910180205945e-05\n",
      "466 2.2747638013242977e-06 1.721663102216553e-05\n",
      "467 2.1983482838550117e-06 1.6767593479016796e-05\n",
      "468 2.125216497006477e-06 1.6329560821759515e-05\n",
      "469 2.054438255072455e-06 1.590407373441849e-05\n",
      "470 1.986860524993972e-06 1.5488833014387637e-05\n",
      "471 1.9201345367036993e-06 1.5084892766026314e-05\n",
      "472 1.8568855466583045e-06 1.469263770559337e-05\n",
      "473 1.7947597825695993e-06 1.43098086482496e-05\n",
      "474 1.7357186834487948e-06 1.3934891285316553e-05\n",
      "475 1.678011017247627e-06 1.357239580102032e-05\n",
      "476 1.6220628822338767e-06 1.321844229096314e-05\n",
      "477 1.5681757759011816e-06 1.2874995263700839e-05\n",
      "478 1.5161390365392435e-06 1.2539088857010938e-05\n",
      "479 1.4652155186922755e-06 1.2212775800435338e-05\n",
      "480 1.4168581401463598e-06 1.1895746865775436e-05\n",
      "481 1.3700855561182834e-06 1.158633403974818e-05\n",
      "482 1.3250132724351715e-06 1.1284873835393228e-05\n",
      "483 1.2804821380996145e-06 1.0991241651936434e-05\n",
      "484 1.2377645361993928e-06 1.070537018676987e-05\n",
      "485 1.1969090110142133e-06 1.0427770575915929e-05\n",
      "486 1.157108727056766e-06 1.0157357792195398e-05\n",
      "487 1.118148702516919e-06 9.89300951914629e-06\n",
      "488 1.0817066140589304e-06 9.635525202611461e-06\n",
      "489 1.0456922154844506e-06 9.386228157381993e-06\n",
      "490 1.0108932428920525e-06 9.143074748863e-06\n",
      "491 9.775794751476496e-07 8.906408766051754e-06\n",
      "492 9.45195893109485e-07 8.674794116814155e-06\n",
      "493 9.138861969404388e-07 8.449486813333351e-06\n",
      "494 8.835845619614702e-07 8.230550520238467e-06\n",
      "495 8.540119438293914e-07 8.017865184228867e-06\n",
      "496 8.258687671514053e-07 7.810045644873753e-06\n",
      "497 7.983822456480993e-07 7.607930456288159e-06\n",
      "498 7.71867007642868e-07 7.410779744532192e-06\n",
      "499 7.464598752449092e-07 7.218641712825047e-06\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables\n",
    "x1 = Variable(torch.randn(N, D_in))\n",
    "y1 = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "x2 = Variable(torch.randn(N, D_in))\n",
    "y2 = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model1 = TwoLayerNet(D_in, H, D_out)\n",
    "model2 = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion1 = torch.nn.MSELoss(size_average=False)\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=1e-4)\n",
    "\n",
    "criterion2 = torch.nn.MSELoss(size_average=False)\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=1e-4)\n",
    "\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred1 = model1(x1)\n",
    "    y_pred2 = model2(x2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss1 = criterion(y_pred1, y1)\n",
    "    loss2 = criterion(y_pred2, y2)\n",
    "    print(t, loss1.data[0], loss2.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer1.zero_grad()\n",
    "    loss1.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss2.backward()\n",
    "    optimizer2.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Multiple NNs - 2\n",
    "\n",
    "In this code block, the 2 NNs are learning with 2 optimizers towards a weighted sum of error. The training emphasized the data fitting of Model2 over Model1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 594.7704467773438 686.4010620117188 1967.572509765625\n",
      "1 551.6640625 586.47412109375 1724.6123046875\n",
      "2 514.5069580078125 511.9692687988281 1538.445556640625\n",
      "3 481.9252014160156 453.1743469238281 1388.27392578125\n",
      "4 452.84967041015625 404.1015319824219 1261.052734375\n",
      "5 426.5615234375 361.7554016113281 1150.072265625\n",
      "6 402.5431823730469 324.2408447265625 1051.02490234375\n",
      "7 380.4490966796875 290.92535400390625 962.2998046875\n",
      "8 360.2560729980469 260.5472412109375 881.3505859375\n",
      "9 341.56781005859375 232.89231872558594 807.3524169921875\n",
      "10 324.1141052246094 207.7465057373047 739.6071166992188\n",
      "11 307.8088073730469 184.8883819580078 677.5855712890625\n",
      "12 292.37786865234375 164.1835174560547 620.744873046875\n",
      "13 277.7117919921875 145.32708740234375 568.365966796875\n",
      "14 263.8661193847656 128.31539916992188 520.4969482421875\n",
      "15 250.75906372070312 113.06564331054688 476.8903503417969\n",
      "16 238.3601837158203 99.46428680419922 437.28875732421875\n",
      "17 226.56414794921875 87.39651489257812 401.357177734375\n",
      "18 215.32135009765625 76.71375274658203 368.74884033203125\n",
      "19 204.5626983642578 67.28390502929688 339.1304931640625\n",
      "20 194.31689453125 58.98806381225586 312.29302978515625\n",
      "21 184.50732421875 51.71034240722656 287.9280090332031\n",
      "22 175.14549255371094 45.334964752197266 265.8154296875\n",
      "23 166.23410034179688 39.75783920288086 245.74978637695312\n",
      "24 157.75352478027344 34.889198303222656 227.53192138671875\n",
      "25 149.6730194091797 30.633394241333008 210.93980407714844\n",
      "26 141.9730682373047 26.924280166625977 195.82162475585938\n",
      "27 134.63394165039062 23.681570053100586 181.99708557128906\n",
      "28 127.63945770263672 20.849071502685547 169.3376007080078\n",
      "29 120.99159240722656 18.36875343322754 157.72909545898438\n",
      "30 114.68994140625 16.198352813720703 147.08663940429688\n",
      "31 108.69508361816406 14.30272388458252 137.300537109375\n",
      "32 102.95742797851562 12.642440795898438 128.2423095703125\n",
      "33 97.51371002197266 11.186660766601562 119.88703155517578\n",
      "34 92.36536407470703 9.908761024475098 112.1828842163086\n",
      "35 87.48310089111328 8.790426254272461 105.06394958496094\n",
      "36 82.85617065429688 7.804357528686523 98.46488952636719\n",
      "37 78.47967529296875 6.93439245223999 92.34845733642578\n",
      "38 74.34429168701172 6.167938232421875 86.68016815185547\n",
      "39 70.43036651611328 5.492634296417236 81.41563415527344\n",
      "40 66.70271301269531 4.896399021148682 76.49551391601562\n",
      "41 63.1790771484375 4.369165897369385 71.91741180419922\n",
      "42 59.83980178833008 3.903019428253174 67.64584350585938\n",
      "43 56.6838493347168 3.4913320541381836 63.66651153564453\n",
      "44 53.70393753051758 3.126173973083496 59.95628356933594\n",
      "45 50.88574981689453 2.8020472526550293 56.489845275878906\n",
      "46 48.22307205200195 2.5140342712402344 53.25114059448242\n",
      "47 45.71186065673828 2.2573812007904053 50.22662353515625\n",
      "48 43.33786392211914 2.0284879207611084 47.394840240478516\n",
      "49 41.09224319458008 1.8242528438568115 44.74074935913086\n",
      "50 38.962059020996094 1.6419470310211182 42.24595260620117\n",
      "51 36.948631286621094 1.4790709018707275 39.90677261352539\n",
      "52 35.038360595703125 1.3333956003189087 37.70515060424805\n",
      "53 33.231876373291016 1.2029889822006226 35.637855529785156\n",
      "54 31.527252197265625 1.0863782167434692 33.700008392333984\n",
      "55 29.914827346801758 0.9819729924201965 31.878772735595703\n",
      "56 28.392257690429688 0.8884689807891846 30.1691951751709\n",
      "57 26.95381736755371 0.8042424917221069 28.562301635742188\n",
      "58 25.593156814575195 0.7285680770874023 27.05029296875\n",
      "59 24.305767059326172 0.6605837345123291 25.626934051513672\n",
      "60 23.087480545043945 0.5994443297386169 24.28636932373047\n",
      "61 21.935606002807617 0.5441718101501465 23.023948669433594\n",
      "62 20.84543228149414 0.49434223771095276 21.834115982055664\n",
      "63 19.815507888793945 0.4493959844112396 20.71430015563965\n",
      "64 18.839128494262695 0.40886640548706055 19.6568603515625\n",
      "65 17.915281295776367 0.37220555543899536 18.659692764282227\n",
      "66 17.040861129760742 0.3390122950077057 17.71888542175293\n",
      "67 16.21224594116211 0.3089723587036133 16.830190658569336\n",
      "68 15.425241470336914 0.28175273537635803 15.988746643066406\n",
      "69 14.679418563842773 0.25706514716148376 15.193549156188965\n",
      "70 13.971638679504395 0.2346125841140747 14.440863609313965\n",
      "71 13.30063247680664 0.21422916650772095 13.729090690612793\n",
      "72 12.664130210876465 0.19572295248508453 13.05557632446289\n",
      "73 12.060510635375977 0.17892365157604218 12.418357849121094\n",
      "74 11.488850593566895 0.16365447640419006 11.81615924835205\n",
      "75 10.946218490600586 0.14975564181804657 11.245729446411133\n",
      "76 10.431368827819824 0.1370995044708252 10.705568313598633\n",
      "77 9.942841529846191 0.1255762130022049 10.19399356842041\n",
      "78 9.478924751281738 0.11508270353078842 9.709090232849121\n",
      "79 9.03825855255127 0.10552037507295609 9.249299049377441\n",
      "80 8.619803428649902 0.09680908918380737 8.813421249389648\n",
      "81 8.2223539352417 0.0888546034693718 8.400063514709473\n",
      "82 7.8441338539123535 0.08158650249242783 8.007307052612305\n",
      "83 7.484267711639404 0.07493714988231659 7.63414192199707\n",
      "84 7.142651081085205 0.0688493549823761 7.2803497314453125\n",
      "85 6.817697048187256 0.06327629834413528 6.944249629974365\n",
      "86 6.508303642272949 0.058178991079330444 6.624661445617676\n",
      "87 6.214043140411377 0.05351248010993004 6.321068286895752\n",
      "88 5.934910774230957 0.04924214631319046 6.033395290374756\n",
      "89 5.669240951538086 0.04533514752984047 5.759911060333252\n",
      "90 5.416390419006348 0.04175280034542084 5.499896049499512\n",
      "91 5.176222324371338 0.03846649080514908 5.25315523147583\n",
      "92 4.947327136993408 0.03545096144080162 5.018229007720947\n",
      "93 4.729092121124268 0.03268194943666458 4.7944560050964355\n",
      "94 4.5215535163879395 0.030136408284306526 4.581826210021973\n",
      "95 4.323847770690918 0.027798080816864967 4.379444122314453\n",
      "96 4.135293483734131 0.02564949356019497 4.1865925788879395\n",
      "97 3.955454111099243 0.023674849420785904 4.002803802490234\n",
      "98 3.784087657928467 0.021857254207134247 3.8278021812438965\n",
      "99 3.6209070682525635 0.020184006541967392 3.6612751483917236\n",
      "100 3.4652225971221924 0.018645917996764183 3.502514362335205\n",
      "101 3.3167130947113037 0.01722727343440056 3.351167678833008\n",
      "102 3.175013303756714 0.01592070236802101 3.206854820251465\n",
      "103 3.03997540473938 0.014717547222971916 3.069410562515259\n",
      "104 2.9111430644989014 0.013607997447252274 2.938359022140503\n",
      "105 2.7881877422332764 0.012584052979946136 2.8133559226989746\n",
      "106 2.671337604522705 0.011639988049864769 2.694617509841919\n",
      "107 2.5598533153533936 0.010769810527563095 2.581393003463745\n",
      "108 2.453294515609741 0.009966476820409298 2.4732275009155273\n",
      "109 2.351522922515869 0.009224558249115944 2.369971990585327\n",
      "110 2.254366397857666 0.00853998214006424 2.271446466445923\n",
      "111 2.161515951156616 0.007907592691481113 2.1773312091827393\n",
      "112 2.0727951526641846 0.007322981022298336 2.0874412059783936\n",
      "113 1.9880470037460327 0.006783038843423128 2.001613140106201\n",
      "114 1.9070149660110474 0.006283895578235388 1.919582724571228\n",
      "115 1.8295334577560425 0.005822437349706888 1.841178297996521\n",
      "116 1.7555572986602783 0.005396031774580479 1.7663493156433105\n",
      "117 1.6847578287124634 0.005001523997634649 1.6947609186172485\n",
      "118 1.6169414520263672 0.004636465571820736 1.6262143850326538\n",
      "119 1.552146553993225 0.004298723302781582 1.560744047164917\n",
      "120 1.490066647529602 0.003986487630754709 1.4980396032333374\n",
      "121 1.4306201934814453 0.0036972598172724247 1.4380147457122803\n",
      "122 1.3737366199493408 0.003429570235311985 1.3805958032608032\n",
      "123 1.319321870803833 0.003181707113981247 1.3256852626800537\n",
      "124 1.2672226428985596 0.0029523184057325125 1.2731273174285889\n",
      "125 1.2173289060592651 0.0027396040968596935 1.2228081226348877\n",
      "126 1.169527530670166 0.002542580012232065 1.1746126413345337\n",
      "127 1.1237558126449585 0.002360008656978607 1.1284757852554321\n",
      "128 1.079889178276062 0.0021908367052674294 1.0842708349227905\n",
      "129 1.0378855466842651 0.0020340606570243835 1.041953682899475\n",
      "130 0.9976412057876587 0.0018887420883402228 1.0014187097549438\n",
      "131 0.9590963125228882 0.0017540935659781098 0.9626045227050781\n",
      "132 0.9221014380455017 0.0016291753854602575 0.9253597855567932\n",
      "133 0.886715829372406 0.0015133098931983113 0.8897424340248108\n",
      "134 0.8527917265892029 0.0014058289816603065 0.8556033968925476\n",
      "135 0.820254921913147 0.0013061820063740015 0.8228672742843628\n",
      "136 0.789074718952179 0.0012136735022068024 0.791502058506012\n",
      "137 0.7591239213943481 0.0011278726160526276 0.7613796591758728\n",
      "138 0.7303898930549622 0.0010482361540198326 0.732486367225647\n",
      "139 0.7028377652168274 0.0009743146947585046 0.7047864198684692\n",
      "140 0.6764084100723267 0.0009057022398337722 0.6782197952270508\n",
      "141 0.6510485410690308 0.0008420060621574521 0.6527325510978699\n",
      "142 0.6267194747924805 0.0007828932139091194 0.62828528881073\n",
      "143 0.6033516526222229 0.0007279636920429766 0.6048075556755066\n",
      "144 0.5809246301651001 0.000676979310810566 0.5822786092758179\n",
      "145 0.5593875646591187 0.0006296231877058744 0.5606468319892883\n",
      "146 0.538733184337616 0.0005856316420249641 0.5399044752120972\n",
      "147 0.5188485383987427 0.0005447659059427679 0.519938051700592\n",
      "148 0.49976783990859985 0.0005067800520919263 0.5007814168930054\n",
      "149 0.481404185295105 0.00047148772864602506 0.48234716057777405\n",
      "150 0.4637641906738281 0.00043868672219105065 0.4646415710449219\n",
      "151 0.44680967926979065 0.0004081955412402749 0.4476260840892792\n",
      "152 0.43052685260772705 0.0003798699763137847 0.43128660321235657\n",
      "153 0.4148772060871124 0.0003535281284712255 0.4155842661857605\n",
      "154 0.39987829327583313 0.00032903015380725265 0.40053635835647583\n",
      "155 0.38543403148651123 0.0003062636824324727 0.38604655861854553\n",
      "156 0.37153568863868713 0.0002850846212822944 0.3721058666706085\n",
      "157 0.3581695556640625 0.00026539521059021354 0.35870033502578735\n",
      "158 0.34532392024993896 0.00024708599084988236 0.34581810235977173\n",
      "159 0.3329605758190155 0.00023006922856438905 0.3334207236766815\n",
      "160 0.32107290625572205 0.0002142267330782488 0.32150137424468994\n",
      "161 0.3096488416194916 0.0001995011989492923 0.31004783511161804\n",
      "162 0.2986467182636261 0.00018580860341899097 0.29901832342147827\n",
      "163 0.28806033730506897 0.00017305865185335279 0.28840646147727966\n",
      "164 0.27787110209465027 0.0001611891930224374 0.27819347381591797\n",
      "165 0.2680632174015045 0.00015016034012660384 0.2683635354042053\n",
      "166 0.2586233615875244 0.0001398784079356119 0.2589031159877777\n",
      "167 0.24954389035701752 0.0001303204771829769 0.2498045265674591\n",
      "168 0.2407986968755722 0.00012141832849010825 0.24104152619838715\n",
      "169 0.23237480223178864 0.0001131282770074904 0.23260106146335602\n",
      "170 0.22426392138004303 0.00010542086965870112 0.22447475790977478\n",
      "171 0.21643780171871185 9.823888831306249e-05 0.21663427352905273\n",
      "172 0.2089029997587204 9.15543787414208e-05 0.2090861052274704\n",
      "173 0.2016434222459793 8.532300853403285e-05 0.20181407034397125\n",
      "174 0.1946520060300827 7.952827581902966e-05 0.19481106102466583\n",
      "175 0.18792590498924255 7.412376726279035e-05 0.18807415664196014\n",
      "176 0.18144270777702332 6.9095563958399e-05 0.18158090114593506\n",
      "177 0.17519278824329376 6.440832657972351e-05 0.17532160878181458\n",
      "178 0.1691744476556778 6.004405440762639e-05 0.169294536113739\n",
      "179 0.16338184475898743 5.597985364147462e-05 0.1634937971830368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 0.157793328166008 5.2191993745509535e-05 0.1578977108001709\n",
      "181 0.15241114795207977 4.86662975163199e-05 0.15250848233699799\n",
      "182 0.1472175121307373 4.53796710644383e-05 0.14730827510356903\n",
      "183 0.14221271872520447 4.231498314766213e-05 0.14229734241962433\n",
      "184 0.1373872309923172 3.945897697121836e-05 0.13746614754199982\n",
      "185 0.1327352374792099 3.680469671962783e-05 0.1328088492155075\n",
      "186 0.12825196981430054 3.433003803365864e-05 0.1283206343650818\n",
      "187 0.12392782419919968 3.2015814213082194e-05 0.12399185448884964\n",
      "188 0.11975573003292084 2.986440813401714e-05 0.11981546133756638\n",
      "189 0.11572994291782379 2.786000186461024e-05 0.11578566581010818\n",
      "190 0.11185193061828613 2.599074286990799e-05 0.11190391331911087\n",
      "191 0.1081082820892334 2.4248076442745514e-05 0.10815677791833878\n",
      "192 0.1044962927699089 2.262299858557526e-05 0.10454154014587402\n",
      "193 0.10101122409105301 2.110616333084181e-05 0.10105343908071518\n",
      "194 0.09764861315488815 1.969280856428668e-05 0.09768799692392349\n",
      "195 0.09440368413925171 1.8376227671978995e-05 0.09444043785333633\n",
      "196 0.09126973897218704 1.7147462131106295e-05 0.09130403399467468\n",
      "197 0.08824591338634491 1.6001360563677736e-05 0.0882779136300087\n",
      "198 0.08533318340778351 1.4933534657757264e-05 0.08536305278539658\n",
      "199 0.08251732587814331 1.3937497897131834e-05 0.0825451985001564\n",
      "200 0.07980240881443024 1.3009797839913517e-05 0.0798284262418747\n",
      "201 0.07718157023191452 1.2141910701757297e-05 0.0772058516740799\n",
      "202 0.07465272396802902 1.1333682778058574e-05 0.07467538863420486\n",
      "203 0.07221242785453796 1.0580296475382056e-05 0.07223358750343323\n",
      "204 0.069858618080616 9.876653166429605e-06 0.06987836956977844\n",
      "205 0.06758127361536026 9.219218554790132e-06 0.06759971380233765\n",
      "206 0.06538093835115433 8.607612471678294e-06 0.06539815664291382\n",
      "207 0.06325602531433105 8.035789505811408e-06 0.06327209621667862\n",
      "208 0.061203792691230774 7.502873359044315e-06 0.06121879816055298\n",
      "209 0.05922209098935127 7.0051155489636585e-06 0.05923610180616379\n",
      "210 0.057309504598379135 6.543328709085472e-06 0.05732259154319763\n",
      "211 0.05545893311500549 6.108800789661473e-06 0.05547115206718445\n",
      "212 0.05367063730955124 5.7044244385906495e-06 0.05368204787373543\n",
      "213 0.05194319784641266 5.327986400516238e-06 0.05195385217666626\n",
      "214 0.05027354508638382 4.975908723281464e-06 0.05028349533677101\n",
      "215 0.0486617386341095 4.646614343073452e-06 0.04867103323340416\n",
      "216 0.04710393771529198 4.3390632527007256e-06 0.04711261764168739\n",
      "217 0.045597489923238754 4.0533282117394265e-06 0.04560559615492821\n",
      "218 0.04414203763008118 3.785063881878159e-06 0.04414960741996765\n",
      "219 0.04273539036512375 3.5361706522962777e-06 0.04274246096611023\n",
      "220 0.04137700796127319 3.302936192994821e-06 0.041383612900972366\n",
      "221 0.040062617510557175 3.0853577754896833e-06 0.04006878659129143\n",
      "222 0.03879184648394585 2.8822471449529985e-06 0.03879760950803757\n",
      "223 0.03756284341216087 2.692556563488324e-06 0.03756823018193245\n",
      "224 0.03637375682592392 2.5161700705211842e-06 0.03637878969311714\n",
      "225 0.03522462770342827 2.350730710531934e-06 0.03522932901978493\n",
      "226 0.034113362431526184 2.197297362727113e-06 0.03411775827407837\n",
      "227 0.033039163798093796 2.0524403225863352e-06 0.0330432690680027\n",
      "228 0.032000117003917694 1.917976760523743e-06 0.03200395405292511\n",
      "229 0.03099551424384117 1.7914228465087945e-06 0.03099909797310829\n",
      "230 0.030022932216525078 1.6746832898206776e-06 0.030026281252503395\n",
      "231 0.029082469642162323 1.5650032310077222e-06 0.02908559888601303\n",
      "232 0.028172459453344345 1.4623878996644635e-06 0.028175383806228638\n",
      "233 0.027292797341942787 1.3670137377630454e-06 0.027295531705021858\n",
      "234 0.02644146978855133 1.2775378763763001e-06 0.026444025337696075\n",
      "235 0.02561742067337036 1.1937415820284514e-06 0.025619808584451675\n",
      "236 0.024821637198328972 1.1161698694195366e-06 0.02482386864721775\n",
      "237 0.02405139058828354 1.0430837846797658e-06 0.024053476750850677\n",
      "238 0.023305652663111687 9.75056309471256e-07 0.02330760285258293\n",
      "239 0.022584978491067886 9.114115187003335e-07 0.022586802020668983\n",
      "240 0.021887559443712234 8.520116239196796e-07 0.02188926376402378\n",
      "241 0.02121143788099289 7.963418511280906e-07 0.021213030442595482\n",
      "242 0.020557144656777382 7.446504923791508e-07 0.020558634772896767\n",
      "243 0.019924312829971313 6.963016403460642e-07 0.019925706088542938\n",
      "244 0.019312087446451187 6.505982241833408e-07 0.0193133894354105\n",
      "245 0.018721316009759903 6.084673600526003e-07 0.01872253231704235\n",
      "246 0.018148938193917274 5.689955173693306e-07 0.018150076270103455\n",
      "247 0.017595240846276283 5.319185447660857e-07 0.017596304416656494\n",
      "248 0.01705908216536045 4.975408387508651e-07 0.01706007681787014\n",
      "249 0.016540050506591797 4.6526790242751304e-07 0.016540981829166412\n",
      "250 0.016037192195653915 4.3500139668140037e-07 0.016038062050938606\n",
      "251 0.015550331212580204 4.0682115809431707e-07 0.015551145188510418\n",
      "252 0.015078750438988209 3.8042290384510125e-07 0.01507951132953167\n",
      "253 0.014622568152844906 3.55633432036484e-07 0.014623279683291912\n",
      "254 0.014180690050125122 3.329874971313984e-07 0.014181355945765972\n",
      "255 0.013752367347478867 3.1130713296079193e-07 0.013752990402281284\n",
      "256 0.01333723682910204 2.911075398515095e-07 0.013337818905711174\n",
      "257 0.012935254722833633 2.7238817779107194e-07 0.012935799546539783\n",
      "258 0.012546245940029621 2.546563564465032e-07 0.012546755373477936\n",
      "259 0.01216926146298647 2.3816137684207206e-07 0.012169737368822098\n",
      "260 0.011804168112576008 2.2288614331955614e-07 0.011804614216089249\n",
      "261 0.011450565420091152 2.0860613858530996e-07 0.01145098265260458\n",
      "262 0.011107932776212692 1.9498902759096381e-07 0.011108323000371456\n",
      "263 0.010776358656585217 1.8255151701396244e-07 0.010776723735034466\n",
      "264 0.010454969480633736 1.708294377067432e-07 0.01045531127601862\n",
      "265 0.01014326699078083 1.5964789668032608e-07 0.010143586434423923\n",
      "266 0.009841089136898518 1.4957610972032853e-07 0.00984138809144497\n",
      "267 0.009548033587634563 1.3977467006043298e-07 0.009548312984406948\n",
      "268 0.00926403421908617 1.3092439132833533e-07 0.009264295920729637\n",
      "269 0.008988117799162865 1.2256765558049665e-07 0.008988362736999989\n",
      "270 0.008720611222088337 1.146601249502055e-07 0.008720840327441692\n",
      "271 0.008461269550025463 1.0726634513957833e-07 0.008461483754217625\n",
      "272 0.008209999650716782 1.0037864228706894e-07 0.008210200816392899\n",
      "273 0.007966585457324982 9.380391929880716e-08 0.00796677265316248\n",
      "274 0.007730886805802584 8.785977456682303e-08 0.007731062360107899\n",
      "275 0.0075019346550107 8.22298034108826e-08 0.00750209903344512\n",
      "276 0.007280227728188038 7.697892812075224e-08 0.007280381862074137\n",
      "277 0.007065293379127979 7.206741514664827e-08 0.007065437734127045\n",
      "278 0.006856908556073904 6.740013702710712e-08 0.006857043132185936\n",
      "279 0.0066548739559948444 6.30627283726426e-08 0.006655000150203705\n",
      "280 0.006459161639213562 5.905184252696927e-08 0.006459279917180538\n",
      "281 0.006269360892474651 5.52742243087323e-08 0.006269471254199743\n",
      "282 0.006085284985601902 5.170910455376543e-08 0.006085388362407684\n",
      "283 0.005907009821385145 4.8350312198408574e-08 0.005907106678932905\n",
      "284 0.00573402876034379 4.534697239932939e-08 0.005734119564294815\n",
      "285 0.005566243547946215 4.246936669005663e-08 0.005566328298300505\n",
      "286 0.005403498653322458 3.979903695494613e-08 0.005403578281402588\n",
      "287 0.005245732143521309 3.724665731397181e-08 0.005245806649327278\n",
      "288 0.005092754028737545 3.48907178704394e-08 0.005092823877930641\n",
      "289 0.0049444520846009254 3.268144510570892e-08 0.0049445172771811485\n",
      "290 0.004800497554242611 3.063572862060937e-08 0.0048005590215325356\n",
      "291 0.004660919774323702 2.8636687687821905e-08 0.004660977050662041\n",
      "292 0.004525710828602314 2.680376809394147e-08 0.004525764379650354\n",
      "293 0.004394402727484703 2.5190413310838267e-08 0.004394453018903732\n",
      "294 0.004267251584678888 2.3596660625457844e-08 0.004267298616468906\n",
      "295 0.00414368836209178 2.2063396443172678e-08 0.004143732599914074\n",
      "296 0.004023770336061716 2.069574023266796e-08 0.0040238117799162865\n",
      "297 0.003907376434653997 1.9362843772796623e-08 0.003907415084540844\n",
      "298 0.0037945208605378866 1.817530659309341e-08 0.0037945571821182966\n",
      "299 0.0036850415635854006 1.704305674365969e-08 0.003685075556859374\n",
      "300 0.003578827017918229 1.5941161279897642e-08 0.0035788589157164097\n",
      "301 0.003475730773061514 1.494453627515213e-08 0.0034757605753839016\n",
      "302 0.0033756515476852655 1.4037254914001096e-08 0.0033756797201931477\n",
      "303 0.003278651973232627 1.3166244094975355e-08 0.00327867828309536\n",
      "304 0.0031844761688262224 1.2354681722115401e-08 0.0031845008488744497\n",
      "305 0.0030930531211197376 1.1625029827655453e-08 0.003093076404184103\n",
      "306 0.003004331374540925 1.0899731783808875e-08 0.0030043532606214285\n",
      "307 0.0029182457365095615 1.0234971981049057e-08 0.002918266225606203\n",
      "308 0.0028347193729132414 9.635215292291832e-09 0.0028347386978566647\n",
      "309 0.002753653097897768 9.065182382528292e-09 0.002753671258687973\n",
      "310 0.0026749875396490097 8.506002124875067e-09 0.0026750045362859964\n",
      "311 0.002598630264401436 7.99430743825269e-09 0.002598646329715848\n",
      "312 0.002524561481550336 7.552681147160456e-09 0.0025245766155421734\n",
      "313 0.002452525543048978 7.0745955760287416e-09 0.0024525397457182407\n",
      "314 0.0023826532997190952 6.639035099453849e-09 0.0023826665710657835\n",
      "315 0.0023149223998188972 6.240534311530155e-09 0.0023149349726736546\n",
      "316 0.002249151701107621 5.88515813859658e-09 0.0022491635754704475\n",
      "317 0.002185333054512739 5.565024885356706e-09 0.0021853442303836346\n",
      "318 0.002123333513736725 5.265018199196447e-09 0.0021233439911156893\n",
      "319 0.0020631493534892797 4.959828103778818e-09 0.002063159365206957\n",
      "320 0.0020047398284077644 4.685225096778822e-09 0.0020047491416335106\n",
      "321 0.0019479455659165978 4.427147093366557e-09 0.0019479544134810567\n",
      "322 0.0018928187200799584 4.176594181615201e-09 0.00189282710198313\n",
      "323 0.001839319011196494 3.9337013646445484e-09 0.0018393269274383783\n",
      "324 0.0017873933538794518 3.7240717176700855e-09 0.0017874008044600487\n",
      "325 0.0017369569977745414 3.5224207994843937e-09 0.0017369640991091728\n",
      "326 0.0016879652393981814 3.3297475887650307e-09 0.0016879718750715256\n",
      "327 0.0016404149355366826 3.17015147466293e-09 0.0016404212219640613\n",
      "328 0.001594285131432116 3.0201341427726902e-09 0.001594291185028851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329 0.0015493851387873292 2.8544124841545226e-09 0.0015493908431380987\n",
      "330 0.0015058252029120922 2.712691182793492e-09 0.001505830674432218\n",
      "331 0.0014635006664320827 2.582891678315491e-09 0.001463505788706243\n",
      "332 0.0014224231708794832 2.465156079267672e-09 0.001422428060323\n",
      "333 0.0013825080823153257 2.3434796325716434e-09 0.0013825127389281988\n",
      "334 0.0013437579618766904 2.229349371773992e-09 0.0013437623856589198\n",
      "335 0.001306110993027687 2.1342823064429695e-09 0.0013061153003945947\n",
      "336 0.0012695828918367624 2.0386470289679437e-09 0.0012695869663730264\n",
      "337 0.001234067720361054 1.948490924164048e-09 0.0012340715620666742\n",
      "338 0.0011995721142739058 1.8535110113404585e-09 0.0011995758395642042\n",
      "339 0.0011660514865070581 1.769863144929218e-09 0.001166054978966713\n",
      "340 0.0011335352901369333 1.7047414591075949e-09 0.0011335386661812663\n",
      "341 0.0011019294615834951 1.6204112496254197e-09 0.0011019327212125063\n",
      "342 0.0010712083894759417 1.5565588817878506e-09 0.001071211532689631\n",
      "343 0.0010413570562377572 1.4991782260054265e-09 0.0010413600830361247\n",
      "344 0.0010123620741069317 1.4358360056476727e-09 0.0010123649844899774\n",
      "345 0.0009841971332207322 1.3876196858220169e-09 0.000984199927188456\n",
      "346 0.0009568444802425802 1.3343505189666871e-09 0.0009568471577949822\n",
      "347 0.0009302730904892087 1.2867445997599702e-09 0.0009302756516262889\n",
      "348 0.0009044537437148392 1.24084409414138e-09 0.0009044562466442585\n",
      "349 0.0008793550077825785 1.1941677646731819e-09 0.0008793573942966759\n",
      "350 0.0008550368365831673 1.153457218627807e-09 0.0008550391648896039\n",
      "351 0.0008313212310895324 1.1194022375704549e-09 0.0008313234429806471\n",
      "352 0.0008082896238192916 1.0762104540873452e-09 0.0008082917775027454\n",
      "353 0.0007859089528210461 1.029989982193058e-09 0.0007859109900891781\n",
      "354 0.000764183234423399 9.991076854731773e-10 0.00076418521348387\n",
      "355 0.0007430753903463483 9.714160587037668e-10 0.0007430773111991584\n",
      "356 0.0007225524168461561 9.397322919824092e-10 0.0007225542794913054\n",
      "357 0.0007026076782494783 9.151119861883217e-10 0.0007026094826869667\n",
      "358 0.0006832375656813383 8.89169737838813e-10 0.0006832393701188266\n",
      "359 0.0006644253735430539 8.549605468033405e-10 0.0006644270615652204\n",
      "360 0.0006461198790930212 8.307625698478205e-10 0.0006461215671151876\n",
      "361 0.0006283321417868137 8.046780464177061e-10 0.0006283337716013193\n",
      "362 0.0006110476097092032 7.760742604112636e-10 0.0006110491813160479\n",
      "363 0.000594243174418807 7.487701014774473e-10 0.0005942446878179908\n",
      "364 0.000577913539018482 7.243348143504136e-10 0.0005779149942100048\n",
      "365 0.0005620267475023866 7.091476295073562e-10 0.0005620281444862485\n",
      "366 0.0005465935682877898 6.946098696225533e-10 0.0005465949652716517\n",
      "367 0.0005316160386428237 6.707230881808357e-10 0.0005316173774190247\n",
      "368 0.0005170282092876732 6.569524368948976e-10 0.0005170295480638742\n",
      "369 0.0005028629093430936 6.363433113776296e-10 0.0005028641899116337\n",
      "370 0.0004890811396762729 6.187215739750229e-10 0.000489082362037152\n",
      "371 0.00047571954200975597 6.053293422070283e-10 0.00047572076437063515\n",
      "372 0.0004627027956303209 5.91990956255728e-10 0.00046270398888736963\n",
      "373 0.00045003709965385497 5.763446386808369e-10 0.00045003826380707324\n",
      "374 0.0004377475124783814 5.704337002754301e-10 0.0004377486475277692\n",
      "375 0.0004257982363924384 5.52086210081626e-10 0.00042579934233799577\n",
      "376 0.0004141787358094007 5.411469050642381e-10 0.0004141798126511276\n",
      "377 0.0004028826078865677 5.299314320694748e-10 0.00040288365562446415\n",
      "378 0.0003919079026672989 5.152581139533652e-10 0.0003919089213013649\n",
      "379 0.0003812275535892695 4.999315406095661e-10 0.00038122854311950505\n",
      "380 0.00037085782969370484 4.887441562573258e-10 0.00037085881922394037\n",
      "381 0.0003607615362852812 4.770716044433243e-10 0.00036076249671168625\n",
      "382 0.00035095022758468986 4.6378448304018605e-10 0.00035095115890726447\n",
      "383 0.00034139424678869545 4.543651843658125e-10 0.0003413951490074396\n",
      "384 0.0003321099211461842 4.4599338111517284e-10 0.00033211082336492836\n",
      "385 0.00032309049856849015 4.3425407714181574e-10 0.00032309137168340385\n",
      "386 0.0003143120266031474 4.242846074475892e-10 0.00031431287061423063\n",
      "387 0.00030578862060792744 4.2058401206190865e-10 0.0003057894646190107\n",
      "388 0.00029749725945293903 4.078106463634157e-10 0.0002974980743601918\n",
      "389 0.00028943122015334666 3.992168262634266e-10 0.000289432005956769\n",
      "390 0.00028159230714663863 3.9169611998346454e-10 0.00028159309295006096\n",
      "391 0.00027395610231906176 3.8537462110355136e-10 0.00027395685901865363\n",
      "392 0.00026653549866750836 3.824616734426911e-10 0.00026653625536710024\n",
      "393 0.0002593207755126059 3.721352670460476e-10 0.0002593215322121978\n",
      "394 0.0002523146104067564 3.638483403456405e-10 0.0002523153380025178\n",
      "395 0.00024549206136725843 3.598749076516583e-10 0.00024549278896301985\n",
      "396 0.00023886389681138098 3.539305515332103e-10 0.00023886460985522717\n",
      "397 0.00023240259906742722 3.463348496879348e-10 0.00023240329755935818\n",
      "398 0.00022614732733927667 3.3715272240719685e-10 0.00022614799672737718\n",
      "399 0.00022004589845892042 3.2949146189231726e-10 0.0002200465532951057\n",
      "400 0.0002141112636309117 3.269688408913396e-10 0.00021411191846709698\n",
      "401 0.00020834477618336678 3.21432658267895e-10 0.00020834541646763682\n",
      "402 0.0002027287846431136 3.1550650980705086e-10 0.00020272941037546843\n",
      "403 0.0001972696918528527 3.087196054352148e-10 0.0001972703030332923\n",
      "404 0.00019196259381715208 3.0571320475125674e-10 0.00019196320499759167\n",
      "405 0.0001867962855612859 3.002475490454515e-10 0.00018679688218981028\n",
      "406 0.00018176977755501866 2.9309568660984553e-10 0.0001817703596316278\n",
      "407 0.00017688357911538333 2.8983671018778523e-10 0.00017688416119199246\n",
      "408 0.0001721322041703388 2.855030656334634e-10 0.00017213277169503272\n",
      "409 0.00016751319344621152 2.7734423091452243e-10 0.0001675137464189902\n",
      "410 0.00016301815048791468 2.751258942890189e-10 0.00016301870346069336\n",
      "411 0.0001586487196618691 2.707265800427905e-10 0.00015864925808273256\n",
      "412 0.0001543936668895185 2.641550589377317e-10 0.00015439419075846672\n",
      "413 0.00015025673201307654 2.640124507902186e-10 0.00015025725588202477\n",
      "414 0.00014623432070948184 2.590996861506767e-10 0.00014623484457843006\n",
      "415 0.00014231317618396133 2.5360227806636715e-10 0.00014231368550099432\n",
      "416 0.00013850686082150787 2.5158786165491165e-10 0.00013850737013854086\n",
      "417 0.00013479567132890224 2.450176450619068e-10 0.00013479616609402\n",
      "418 0.00013119183131493628 2.4347937555013743e-10 0.00013119231152813882\n",
      "419 0.00012768681335728616 2.362270656863785e-10 0.00012768727901857346\n",
      "420 0.00012426823377609253 2.330825810137327e-10 0.00012426869943737984\n",
      "421 0.00012095057172700763 2.2843649194470572e-10 0.00012095103011233732\n",
      "422 0.00011771891877287999 2.2477618377703124e-10 0.00011771936988225207\n",
      "423 0.00011458018707344308 2.2239485253372493e-10 0.00011458063090685755\n",
      "424 0.00011152539809700102 2.1919271953052544e-10 0.00011152583465445787\n",
      "425 0.00010855423170141876 2.161737872041769e-10 0.000108554660982918\n",
      "426 0.00010566163109615445 2.121286202250161e-10 0.00010566205310169607\n",
      "427 0.00010284958261763677 2.0946662460108456e-10 0.00010285000462317839\n",
      "428 0.00010010737605625764 2.0778495590789703e-10 0.00010010779078584164\n",
      "429 9.744533599587157e-05 2.050846159562525e-10 9.744574344949797e-05\n",
      "430 9.485301416134462e-05 2.0353646545956394e-10 9.485342161497101e-05\n",
      "431 9.233095624949783e-05 1.980028085935004e-10 9.2331349151209e-05\n",
      "432 8.987849287223071e-05 1.9424438446602466e-10 8.987887849798426e-05\n",
      "433 8.748911932343617e-05 1.9285471830610135e-10 8.748950494918972e-05\n",
      "434 8.516456728102639e-05 1.88982607340904e-10 8.516494563082233e-05\n",
      "435 8.290263212984428e-05 1.8676252211413669e-10 8.29030032036826e-05\n",
      "436 8.070125477388501e-05 1.8487184005877566e-10 8.070162584772334e-05\n",
      "437 7.85614611231722e-05 1.8342342922306187e-10 7.85618249210529e-05\n",
      "438 7.648021710338071e-05 1.8151795344589772e-10 7.648058090126142e-05\n",
      "439 7.444910443155095e-05 1.7554457887314356e-10 7.444945367751643e-05\n",
      "440 7.247849862324074e-05 1.7473096580733483e-10 7.247884786920622e-05\n",
      "441 7.055925379972905e-05 1.7301551857862307e-10 7.055960304569453e-05\n",
      "442 6.868972559459507e-05 1.7121823403520864e-10 6.869006756460294e-05\n",
      "443 6.6870627051685e-05 1.681238342987612e-10 6.687096174573526e-05\n",
      "444 6.510299863293767e-05 1.6505541378109e-10 6.510332605103031e-05\n",
      "445 6.338040839182213e-05 1.6332556140863375e-10 6.338073580991477e-05\n",
      "446 6.170396227389574e-05 1.6091009080732022e-10 6.170428241603076e-05\n",
      "447 6.0073092754464597e-05 1.5785803220147443e-10 6.0073409258620813e-05\n",
      "448 5.8486675698077306e-05 1.5695711397256673e-10 5.8486988564254716e-05\n",
      "449 5.694007995771244e-05 1.5387503771169264e-10 5.6940389185911044e-05\n",
      "450 5.543523366213776e-05 1.5376695750024538e-10 5.5435542890336365e-05\n",
      "451 5.397447966970503e-05 1.5340635706184713e-10 5.397478525992483e-05\n",
      "452 5.255122960079461e-05 1.5222394178504572e-10 5.255153519101441e-05\n",
      "453 5.116492320667021e-05 1.5010694076611486e-10 5.11652251589112e-05\n",
      "454 4.981739039067179e-05 1.4799733660808556e-10 4.9817685066955164e-05\n",
      "455 4.850635741604492e-05 1.4736460662856388e-10 4.8506652092328295e-05\n",
      "456 4.7224442823790014e-05 1.4636795941935787e-10 4.722473386209458e-05\n",
      "457 4.598419400281273e-05 1.441811253721781e-10 4.598448140313849e-05\n",
      "458 4.477187758311629e-05 1.419584033657273e-10 4.4772161345463246e-05\n",
      "459 4.3594227463472635e-05 1.4005469006761473e-10 4.359450758784078e-05\n",
      "460 4.244413139531389e-05 1.4000825498960978e-10 4.2444411519682035e-05\n",
      "461 4.1329822124680504e-05 1.374980546087201e-10 4.133009861106984e-05\n",
      "462 4.024252848466858e-05 1.3571034573889307e-10 4.0242801333079115e-05\n",
      "463 3.918596121366136e-05 1.3486474437218732e-10 3.918623042409308e-05\n",
      "464 3.81541540264152e-05 1.3159515144245404e-10 3.815441596088931e-05\n",
      "465 3.7150697608012706e-05 1.3216738814492146e-10 3.7150963180465624e-05\n",
      "466 3.6178073060000315e-05 1.2870605969883542e-10 3.617833135649562e-05\n",
      "467 3.522531551425345e-05 1.2694567619320196e-10 3.522557017276995e-05\n",
      "468 3.4300657716812566e-05 1.2570945673306966e-10 3.4300908737350255e-05\n",
      "469 3.3398970117559657e-05 1.2442202823592652e-10 3.339921750011854e-05\n",
      "470 3.252419628552161e-05 1.23407437047085e-10 3.2524443668080494e-05\n",
      "471 3.1672403565607965e-05 1.2169237839643188e-10 3.167264731018804e-05\n",
      "472 3.084280251641758e-05 1.2112770508831971e-10 3.084304626099765e-05\n",
      "473 3.0035544114070944e-05 1.19783127860984e-10 3.0035784220672213e-05\n",
      "474 2.924761429312639e-05 1.2002479565786928e-10 2.9247854399727657e-05\n",
      "475 2.8481275876401924e-05 1.1830936230694533e-10 2.8481512345024385e-05\n",
      "476 2.7736665288102813e-05 1.1752919470975343e-10 2.773689993773587e-05\n",
      "477 2.7010184567188844e-05 1.165006979775285e-10 2.7010417397832498e-05\n",
      "478 2.630371272971388e-05 1.1482562123354967e-10 2.6303941922378726e-05\n",
      "479 2.5616735001676716e-05 1.1362184804131203e-10 2.561696237535216e-05\n",
      "480 2.4945342374849133e-05 1.1376548314512291e-10 2.4945569748524576e-05\n",
      "481 2.4292967282235622e-05 1.1220568918446361e-10 2.429319101793226e-05\n",
      "482 2.3659335056436248e-05 1.1057357807153778e-10 2.365955697314348e-05\n",
      "483 2.3041528038447723e-05 1.1039801017798112e-10 2.3041748136165552e-05\n",
      "484 2.2437787265516818e-05 1.090093848521434e-10 2.2438005544245243e-05\n",
      "485 2.185174344049301e-05 1.0750068890619247e-10 2.185195808124263e-05\n",
      "486 2.1281599401845597e-05 1.0571084285704302e-10 2.1281810404616408e-05\n",
      "487 2.07259308808716e-05 1.0662985772125211e-10 2.0726143702631816e-05\n",
      "488 2.0184883396723308e-05 1.037743641019162e-10 2.0185090761515312e-05\n",
      "489 1.9660312318592332e-05 1.0280397366724259e-10 1.9660517864394933e-05\n",
      "490 1.9148337742080912e-05 1.0290543417390552e-10 1.9148543287883513e-05\n",
      "491 1.8648926925379783e-05 1.043446024029393e-10 1.864913610916119e-05\n",
      "492 1.8162192645831965e-05 1.0285644558294393e-10 1.8162398191634566e-05\n",
      "493 1.7689291780698113e-05 1.0007691897406801e-10 1.7689491869532503e-05\n",
      "494 1.7228790966328233e-05 9.766071285000066e-11 1.7228985598194413e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495 1.6781363228801638e-05 9.747200269139e-11 1.6781557860667817e-05\n",
      "496 1.634359432500787e-05 9.642085740946271e-11 1.6343787137884647e-05\n",
      "497 1.5918749340926297e-05 9.630626851553359e-11 1.5918942153803073e-05\n",
      "498 1.5503555914619938e-05 9.48482542506568e-11 1.5503745089517906e-05\n",
      "499 1.5101551070983987e-05 9.409842349761277e-11 1.5101739336387254e-05\n"
     ]
    }
   ],
   "source": [
    "#from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables\n",
    "x1 = Variable(torch.randn(N, D_in))\n",
    "y1 = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "x2 = Variable(torch.randn(N, D_in))\n",
    "y2 = Variable(torch.randn(N, D_out), requires_grad=False)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model1 = TwoLayerNet(D_in, H, D_out)\n",
    "model2 = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "params = (list)\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=1e-4)\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=1e-4)\n",
    "\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred1 = model1(x1)\n",
    "    y_pred2 = model2(x2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss1 = criterion(y_pred1, y1)\n",
    "    loss2 = criterion(y_pred2, y2)\n",
    "    loss = 1.0*loss1 + 2.0*loss2   # The higher weight --> greater fitting\n",
    "    \n",
    "    print(t, loss1.data[0], loss2.data[0], loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    \n",
    "    loss.backward()    # Backprop on loss - which is a weighted sum of loss1 and loss2\n",
    "    \n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load agent 0\n",
      "Load agent 1\n",
      "Load agent 2\n",
      "Load agent 3\n",
      "[4, 4, 4, 7]\n",
      "[0, 4, 4, 6]\n",
      "[0, 3, 4, 6]\n",
      "[1, 1, 0, 0]\n",
      "[4, 0, 0, 0]\n",
      "[4, 7, 6, 3]\n",
      "[6, 6, 0, 7]\n",
      "[0, 2, 0, 2]\n",
      "[0, 7, 0, 7]\n",
      "[3, 1, 3, 0]\n",
      "[6, 0, 6, 0]\n",
      "[2, 1, 1, 5]\n",
      "[1, 1, 6, 3]\n",
      "[3, 1, 0, 1]\n",
      "[0, 1, 3, 7]\n",
      "[3, 5, 6, 3]\n",
      "[6, 1, 5, 2]\n",
      "[3, 6, 1, 1]\n",
      "[3, 1, 0, 1]\n",
      "[0, 1, 0, 7]\n",
      "[6, 6, 1, 4]\n",
      "[7, 0, 1, 5]\n",
      "[7, 6, 1, 7]\n",
      "[1, 0, 3, 2]\n",
      "[6, 1, 0, 2]\n",
      "[1, 6, 0, 0]\n",
      "[6, 5, 3, 7]\n",
      "[0, 4, 2, 5]\n",
      "[4, 2, 0, 7]\n",
      "[6, 1, 1, 4]\n",
      "[0, 4, 6, 1]\n",
      "[0, 1, 0, 4]\n",
      "[3, 1, 6, 0]\n",
      "[4, 2, 5, 6]\n",
      "[6, 7, 0, 5]\n",
      "[0, 1, 6, 2]\n",
      "[2, 6, 5, 4]\n",
      "[6, 0, 0, 7]\n",
      "[4, 1, 3, 7]\n",
      "[4, 6, 0, 0]\n",
      "[0, 0, 7, 7]\n",
      "[4, 0, 0, 3]\n",
      "[1, 6, 0, 1]\n",
      "[0, 5, 6, 3]\n",
      "[4, 4, 5, 0]\n",
      "[0, 6, 0, 5]\n",
      "[7, 2, 0, 4]\n",
      "[7, 0, 4, 4]\n",
      "[0, 6, 1, 4]\n",
      "[1, 6, 1, 0]\n",
      "[6, 5, 4, 0]\n",
      "[1, 1, 1, 4]\n",
      "[4, 0, 6, 5]\n",
      "[6, 6, 5, 6]\n",
      "[7, 6, 5, 2]\n",
      "[4, 1, 0, 3]\n",
      "[6, 6, 5, 5]\n",
      "[1, 6, 6, 4]\n",
      "[6, 6, 0, 7]\n",
      "[2, 6, 1, 7]\n",
      "[6, 1, 6, 5]\n",
      "[0, 5, 0, 3]\n",
      "[6, 1, 5, 7]\n",
      "[4, 1, 0, 3]\n",
      "[4, 1, 0, 2]\n",
      "[4, 1, 0, 7]\n",
      "[5, 7, 5, 1]\n",
      "[3, 0, 1, 1]\n",
      "[7, 7, 0, 7]\n"
     ]
    }
   ],
   "source": [
    "from model import *    # Use the Policy and Rdn_policy defined in model.py\n",
    "\n",
    "# There will be 4 agents - 3 AI agents, 1 random agent\n",
    "num_ai_agents = 3\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "ai_agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "rewards = []\n",
    "\n",
    "env = GatheringEnv(n_agents=num_agents, map_name='default')\n",
    "\n",
    "# Env API is similar to that of OpenAI Gym\n",
    "state_n = env.reset()\n",
    "env.render()\n",
    "\n",
    "# Load AI agents with trained weights\n",
    "for i in range(num_ai_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Policy(env.state_size, i+1))\n",
    "    ai_agents[i].load_weights()\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load agent {}\".format(i))\n",
    "    ai_agents.append(Rdn_Policy())\n",
    "\n",
    "# Initialize AI and random agent data\n",
    "for i in range(num_agents):\n",
    "    actions = [0 for i in range(num_agents)]\n",
    "    tags = [0 for i in range(num_agents)]\n",
    "    rewards = [0 for i in range(num_agents)]\n",
    "\n",
    "n_steps = 1000\n",
    "\n",
    "# Render for n_steps steps\n",
    "for step in range(n_steps):\n",
    "    # Load AI agent with trained weights\n",
    "    for i in range(num_agents):\n",
    "        actions[i] = ai_agents[i].select_action(state_n[i])\n",
    "        if actions[i] is 6:\n",
    "            tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print (actions)    \n",
    "            \n",
    "    state_n, reward_n, done_n, info_n = env.step(actions)\n",
    "\n",
    "    for i in range(num_agents):\n",
    "        rewards[i] += reward_n[i]    # Accumulate rewards for each agent\n",
    "        \n",
    "    if any(done_n):\n",
    "        break\n",
    "    env.render()\n",
    "    time.sleep(1/30)  # Change speed of video rendering\n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "\n",
    "# Print out statistics of all agents\n",
    "for i in range(num_agents):\n",
    "    print (\"Agent{} aggressiveness is {:.2f}\".format(i+1, tags[i]/n_steps))\n",
    "    print (\"Agent{} reward is {:d}\".format(i+1, rewards[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
